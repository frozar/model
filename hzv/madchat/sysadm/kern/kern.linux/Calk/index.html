<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="GENERATOR" content="Watcom vi 11.0">
<title>Conceptual Architecture of the Linux Kernel</title>
</head>

<body bgcolor="#FFFFFF" text="#000000">

<h1 align="center">Conceptual Architecture of the Linux Kernel</h1>

<h2 align="center"><br>
<br>
<br>
Ivan Bowman<br>
<a href="mailto:ibowman@sybase.com">ibowman@sybase.com</a><br>
<br>
January 1998<br>
<br>
<br>
<br>
<br>
For Ric Holt<br>
CS746G Assignment One<br>
<br>
<br>
<br>
<br>
</h2>

<p align="center"><strong>Available at: </strong><a
href="http://www.grad.math.uwaterloo.ca/~itbowman/CS746G/a1/">http://www.grad.math.uwaterloo.ca/~itbowman/CS746G/a1/</a><br>
</p>

<p align="center"><strong>Keywords:</strong> Software
architecture, conceptual architecture, Linux</p>

<p align="center"><br>
<br>
<br>
<br>
<br>
</p>

<hr size="1" noshade>

<h2 align="center">Abstract</h2>

<blockquote>
    <p align="left">&nbsp;</p>
    <blockquote>
        <p>This paper describes the <em>abstract</em> or <em>conceptual</em>
        software architecture of the Linux kernel. This level of
        architecture is concerned with the large-scale subsystems
        within the kernel, but not with particular procedures or
        variables. One of the purposes of such an abstract
        architecture is to form a mental model for Linux
        developers and architects. The model may not reflect the
        as-built architecture perfectly, but it provides a useful
        way to think about the overall structure. This model is
        most useful for entry-level developers, but is also a
        good way for experienced developers to maintain a
        consistent and accurate system vocabulary.</p>
    </blockquote>
    <blockquote>
        <p>The architecture presented here is the result of
        reverse engineering an existing Linux implementation; the
        primary sources of information used were the
        documentation and source code. Unfortunately, no
        developer interviews were used to extract the live
        architecture of the system.</p>
    </blockquote>
    <blockquote>
        <p>The Linux kernel is composed of five main subsystems
        that communicate using procedure calls. Four of these
        five subsystems are discussed at the module
        interconnection level, and we discuss the architectural
        style in the sense used by <a href="#Ref_Garlan_1994">Garlan
        and Shaw</a>. At all times the relation of particular
        subsystems to the overall Linux system is considered.</p>
    </blockquote>
    <blockquote>
        <p>The architecture of the kernel is one of the reasons
        that Linux has been successfully adopted by many users.
        In particular, the Linux kernel architecture was designed
        to support a large number of volunteer developers.
        Further, the subsystems that are most likely to need
        enhancements were architected to easily support
        extensibility. These two qualities are factors in the
        success of the overall system.</p>
    </blockquote>
</blockquote>

<hr size="1" noshade>

<h1>Contents</h1>

<table border="0">
    <tr>
        <td colspan="2"><a href="#Toc_1"><b>1. Introduction</b></a></td>
    </tr>
    <tr>
        <td>&nbsp;</td>
        <td><a href="#Toc_1_1"><em>1.1 Purpose</em></a></td>
    </tr>
    <tr>
        <td>&nbsp;</td>
        <td><a href="#Toc_1_2"><i>1.2 Challenges of this Paper</i></a></td>
    </tr>
    <tr>
        <td>&nbsp;</td>
        <td><a href="#Toc_1_3"><i>1.3 Organization</i></a></td>
    </tr>
    <tr>
        <td colspan="2"><a href="#Toc_2"><b>2. System
        Architecture</b></a></td>
    </tr>
    <tr>
        <td>&nbsp;</td>
        <td><a href="#Toc_2_1"><i>2.1 System Overview</i></a></td>
    </tr>
    <tr>
        <td>&nbsp;</td>
        <td><a href="#Toc_2_2"><i>2.2 Purpose of the Kernel</i></a></td>
    </tr>
    <tr>
        <td>&nbsp;</td>
        <td><a href="#Toc_2_3"><i>2.3 Overview of the Kernel
        Structure</i></a></td>
    </tr>
    <tr>
        <td>&nbsp;</td>
        <td><a href="#Toc_2_4"><i>2.4 Supporting Multiple
        Developers</i></a></td>
    </tr>
    <tr>
        <td>&nbsp;</td>
        <td><a href="#Toc_2_5"><i>2.5 System Data Structures</i></a></td>
    </tr>
    <tr>
        <td colspan="2"><a href="#Toc_3"><b>3. Subsystem
        Architectures</b></a></td>
    </tr>
    <tr>
        <td>&nbsp;</td>
        <td><a href="#Toc_3_1"><i>3.1 Process Scheduler
        Architecture</i></a></td>
    </tr>
    <tr>
        <td>&nbsp;</td>
        <td><a href="#Toc_3_2"><i>3.2 Memory Manager Architecture</i></a></td>
    </tr>
    <tr>
        <td>&nbsp;</td>
        <td><a href="#Toc_3_3"><i>3.3 Virtual File System
        Architecture</i></a></td>
    </tr>
    <tr>
        <td>&nbsp;</td>
        <td><a href="#Toc_3_4"><i>3.4 Network Interface
        Architecture</i></a></td>
    </tr>
    <tr>
        <td>&nbsp;</td>
        <td><a href="#Toc_3_5"><i>3.5 Inter-Process Communication
        Architecture</i></a></td>
    </tr>
    <tr>
        <td colspan="2"><a href="#Toc_4"><b>4. Conclusions</b></a></td>
    </tr>
    <tr>
        <td colspan="2"><a href="#Toc_Definition"><b>Definition
        of Terms</b></a><b> </b></td>
    </tr>
    <tr>
        <td colspan="2"><a href="#Toc_References"><b>References</b></a><b>
        </b></td>
    </tr>
</table>

<h1>List of Figures</h1>

<table border="0" cellpadding="3">
    <tr>
        <td><a href="#Fig_Layer"><b>Figure 2.1:</b></a></td>
        <td>Decomposition of Linux System into Major Subsystems</td>
    </tr>
    <tr>
        <td><a href="#Fig_Overview1"><b>Figure 2.2:</b></a> </td>
        <td>Kernel Subsystem Overview </td>
    </tr>
    <tr>
        <td><a href="#Fig_Developers"><b>Figure 2.3:</b></a></td>
        <td>Division of Developer Responsibilities</td>
    </tr>
    <tr>
        <td><a href="#Fig_Scheduler"><b>Figure 3.1:</b></a> </td>
        <td>Process Scheduler Subsystem in Context</td>
    </tr>
    <tr>
        <td><a href="#Fig_MMAN"><b>Figure 3.2:</b></a></td>
        <td>Memory Manager subsystem in context</td>
    </tr>
    <tr>
        <td><a href="#Fig_VFS"><b>Figure 3.3:</b></a></td>
        <td>Virtual File System in Context</td>
    </tr>
    <tr>
        <td><a href="#Fig_Net"><b>Figure 3.4:</b></a></td>
        <td>Network Interface Subsystem in Context</td>
    </tr>
</table>

<hr size="1" noshade>

<h1><a name="Toc_1">1. Introduction</a></h1>

<h2><a name="Toc_1_1">1.1 Purpose</a></h2>

<p>The goal of this paper is to present the <em>abstract</em>
architecture of the Linux kernel. This is described by Soni (<a
href="#Ref_Soni_1995">[Soni 1995]</a>) as being the <i>conceptual</i>
architecture. By concentrating on high-level design, this
architecture is useful to entry-level developers that need to see
the high level architecture before understanding where their
changes fit in. In addition, the conceptual architecture is a
good way to create a formal system vocabulary that is shared by
experienced developers and system designers. This architectural
description may not perfectly reflect the actual implementation
architecture, but can provide a useful mental model for all
developers to share. Ideally, the conceptual architecture should
be created before the system is implemented, and should be
updated to be an ongoing system conscience in the sense of <a
href="#Ref_Monroe_1997">[Monroe 1997]</a>, showing clearly the
load-bearing walls as described in <a href="#Ref_Perry_1992">[Perry
1992]</a>.</p>

<h2><a name="Toc_1_2">1.2 Challenges of this Paper</a></h2>

<p>This presentation is somewhat unusual, in that the conceptual
architecture is usually formed before the as-built architecture
is complete. Since the author of this paper was not involved in
either the design or implementation of the Linux system, this
paper is the result of reverse engineering the Slackware 2.0.27
kernel source and documentation. A few architectural descriptions
were used (in particular, <a href="#Ref_Rusling_1997">[Rusling
1997]</a> and <a href="#Ref_Wirzenius_1997">[Wirzenius 1997]</a>
were quite helpful), but these descriptions were also based on
the existing system implementation. By deriving the conceptual
architecture from an existing implementation, this paper probably
presents some implementation details as conceptual architecture.</p>

<p>In addition, the mechanisms used to derive the information in
this paper omitted the best source of information -- the live
knowledge of the system architects and developers. For a proper
abstraction of the system architecture, interviews with these
individuals would be required. Only in this way can an accurate
mental model of the system architecture be described.</p>

<p>Despite these problems, this paper offers a useful
conceptualization of the Linux kernel software, although it
cannot be taken as an accurate depiction of the system as
implemented.</p>

<h2><a name="Toc_1_3">1.3 Organization</a></h2>

<p>The next section describes the overall objective and
architecture of the Linux kernel as a whole. Next, each
individual subsystem is elaborated to the module level, with a
discussion of the relations between modules in a subsystem and to
other subsystems. Finally, we discuss how the architecture of the
Linux kernel was useful in the implementation of the system and
contributed to the overall success of the system.</p>

<p>&nbsp;</p>

<hr size="1" noshade>

<h1><a name="Toc_2">2. System Architecture</a></h1>

<h2><a name="Toc_2_1">2.1 System Overview</a></h2>

<p>The Linux kernel is useless in isolation; it participates as
one part in a larger system that, as a whole, is useful. As such,
it makes sense to discuss the kernel in the context of the entire
system. Figure 2.1 shows a decomposition of the entire Linux
operating system:</p>
<div align="center"><center>

<table border="0" cellpadding="3">
    <tr>
        <td align="center"><a name="Fig_Layer"><img
        src="layer.gif" width="198" height="198"></a></td>
    </tr>
    <tr>
        <td align="center"><strong>Figure 2.1:</strong><em>
        Decomposition of Linux System into Major Subsystems</em></td>
    </tr>
</table>
</center></div>

<p>The Linux operating system is composed of four major
subsystems:</p>

<ol>
    <li><strong>User Applications</strong> -- the set of
        applications in use on a particular Linux system will be
        different depending on what the computer system is used
        for, but typical examples include a word-processing
        application and a web-browser.</li>
    <li><strong>O/S Services </strong>-- these are services that
        are typically considered part of the operating system (a
        windowing system, command shell, etc.); also, the
        programming interface to the kernel (compiler tool and
        library) is included in this subsystem.</li>
    <li><strong>Linux Kernel</strong> -- this is the main area of
        interest in this paper; the kernel abstracts and mediates
        access to the hardware resources, including the CPU.</li>
    <li><strong>Hardware Controllers</strong> -- this subsystem
        is comprised of all the possible physical devices in a
        Linux installation; for example, the CPU, memory
        hardware, hard disks, and network hardware are all
        members of this subsystem</li>
</ol>

<p>This decomposition follows Garlan and Shaw's <em>Layered</em>
style discussed in <a href="#Ref_Garlan_1994">[Garlan 1994]</a>;
each subsystem layer can only communicate with the subsystem
layers that are immediately adjacent to it. In addition, the
dependencies between subsystems are from the top down: layers
pictured near the top depend on lower layers, but subsystems
nearer the bottom do not depend on higher layers.</p>

<p>Since the primary interest of this paper is the Linux kernel,
we will completely ignore the User Applications subsystem, and
only consider the Hardware and O/S Services subsystems to the
extent that they interface with the Linux kernel subsystem.</p>

<p>&nbsp;</p>

<h2><a name="Toc_2_2">2.2 Purpose of the Kernel</a></h2>

<p>The Linux kernel presents a virtual machine interface to user <a
href="#Def_Process">processes</a>. Processes are written without
needing any knowledge of what physical hardware is installed on a
computer -- the Linux kernel abstracts all hardware into a
consistent virtual interface. In addition, Linux supports
multi-tasking in a manner that is transparent to user processes:
each process can act as though it is the only process on the
computer, with exclusive use of main memory and other hardware
resources. The kernel actually runs several processes
concurrently, and is responsible for mediating access to hardware
resources so that each process has fair access while
inter-process security is maintained.</p>

<h2><a name="Toc_2_3">2.3 Overview of the Kernel Structure</a></h2>

<p>The Linux kernel is composed of five main subsystems: </p>

<ol>
    <li>The <a href="#Toc_3_1"><b>Process Scheduler</b></a>
        (SCHED) is responsible for controlling process access to
        the CPU. The scheduler enforces a policy that ensures
        that processes will have fair access to the CPU, while
        ensuring that necessary hardware actions are performed by
        the kernel on time.</li>
    <li>The <a href="#Toc_3_2"><b>Memory Manager</b></a> (MM)
        permits multiple process to securely share the machine's
        main memory system. In addition, the memory manager
        supports virtual memory that allows Linux to support
        processes that use more memory than is available in the
        system. Unused memory is swapped out to persistent
        storage using the file system then swapped back in when
        it is needed.</li>
    <li>The <a href="#Toc_3_3"><b>Virtual File System</b></a><b> </b>(VFS)
        abstracts the details of the variety of hardware devices
        by presenting a common file interface to all devices. In
        addition, the VFS supports several file system formats
        that are compatible with other operating systems.</li>
    <li>The <a href="#Toc_3_4"><b>Network Interface</b></a> (NET)
        provides access to several networking standards and a
        variety of network hardware.</li>
    <li>The <a href="#Toc_3_5"><b>Inter-Process Communication</b></a>
        (IPC) subsystem supports several mechanisms for
        process-to-process communication on a single Linux
        system. </li>
</ol>

<p><a href="#Fig_Overview1">Figure 2.2</a> shows a
high-level decomposition of the Linux kernel, where lines are
drawn from dependent subsystems to the subsystems they depend on:</p>
<div align="center"><center>

<table border="0" cellpadding="3">
    <tr>
        <td align="center"><a name="Fig_Overview1"><img
        src="overview1.gif" width="640" height="456"></a></td>
    </tr>
    <tr>
        <td align="center"><strong>Figure 2.2:</strong><em>
        Kernel Subsystem Overview</em></td>
    </tr>
</table>
</center></div>

<p>&nbsp;</p>

<p>This diagram emphasizes that the most central subsystem is the
process scheduler: all other subsystems depend on the process
scheduler since all subsystems need to suspend and resume
processes. Usually a subsystem will suspend a process that is
waiting for a hardware operation to complete, and resume the
process when the operation is finished. For example, when a
process attempts to send a message across the network, the
network interface may need to suspend the process until the
hardware has completed sending the message successfully. After
the message has been sent (or the hardware returns a failure),
the network interface then resumes the process with a return code
indicating the success or failure of the operation. The other
subsystems (memory manager, virtual file system, and
inter-process communication) all depend on the process scheduler
for similar reasons.</p>

<p>The other dependencies are somewhat less obvious, but equally
important:</p>

<ul>
    <li>The process-scheduler subsystem uses the memory manager
        to adjust the hardware memory map for a specific process
        when that process is resumed. </li>
    <li>The inter-process communication subsystem depends on the
        memory manager to support a shared-memory communication
        mechanism. This mechanism allows two processes to access
        an area of common memory in addition to their usual
        private memory. </li>
    <li>The virtual file system uses the network interface to
        support a network file system (<a href="#Def_NFS">NFS</a>),
        and also uses the memory manager to provide a <a
        href="#Def_Ramdisk">ramdisk</a> device. </li>
    <li>The memory manager uses the virtual file system to
        support <a href="#Def_Swapping">swapping</a>; this is the
        only reason that the memory manager depends on the
        process scheduler. When a process accesses memory that is
        currently swapped out, the memory manager makes a request
        to the file system to fetch the memory from persistent
        storage, and suspends the process. </li>
</ul>

<p>In addition to the dependencies that are shown explicitly, all
subsystems in the kernel rely on some common resources that are
not shown in any subsystem. These include procedures that all
kernel subsystems use to allocate and free memory for the
kernel's use, procedures to print warning or error messages, and
system debugging routines. These resources will not be referred
to explicitly since they are assumed ubiquitously available and
used within the kernel layer of <a href="#Fig_Layer">Figure 2.1</a>.</p>

<p>The architectural style at this level resembles the <i>Data
Abstraction</i> style discussed by Garlan and Shaw in <a
href="#Ref_Garlan_1994">[Garlan 1994]</a>. Each of the depicted
subsystems contains state information that is accessed using a
procedural interface, and the subsystems are each responsible for
maintaining the integrity of their managed resources.</p>

<h2><a name="Toc_2_4">2.4 Supporting Multiple Developers</a></h2>

<p align="left">The Linux system was developed by a large number
of volunteers (the current <a
href="http://sunsite.unc.edu/navigator-bin/navigator.cgi?CREDITS">CREDITS</a>
file lists 196 developers that have worked on the Linux system).
The large number of developers and the fact that they are
volunteers has an impact on how the system should be architected.
With such a large number of geographically dispersed developers,
a tightly coupled system would be quite difficult to develop --
developers would be constantly treading on each others code. For
this reason, the Linux system was architected to have the
subsystems that were anticipated to need the most modification --
the file systems, hardware interfaces, and network system --
designed to be highly modular. For example, an implementation of
Linux can be expected to support many hardware devices which each
have distinct interfaces; a naive architecture would put the
implementation of all hardware devices into one subsystem. An
approach that better supports multiple developers is to separate
the code for each hardware device into a <a
href="#Def_Device_Driver"><i>device driver</i></a> that is a
distinct module in the file system. Analyzing the credits file
gives <a href="#Fig_Developers">Figure 2.3</a>:</p>

<p align="left">&nbsp;</p>
<div align="center"><center>

<table border="0" cellpadding="3">
    <tr>
        <td align="center"><a name="Fig_Developers"><img
        src="developers.gif" width="640" height="702"></a></td>
    </tr>
    <tr>
        <td align="center"><strong>Figure 2.3:</strong><em>
        Division of Developer Responsibilities</em></td>
    </tr>
</table>
</center></div>

<p>&nbsp;</p>

<p><a href="#Fig_Developers">Figure 2.3</a> shows most of the
developers who have worked on the Linux kernel, and the areas
that they appeared to have implemented. A few developers modified
many parts of the kernel; for clarity, these developers were not
included. For example, Linus Torvalds was the original
implementor of most of the kernel subsystems, although subsequent
development was done by others. This diagram can't be considered
accurate because developer signatures were not maintained
consistently during the development of the kernel, but it gives a
general idea of what systems developers spent most of their
effort implementing.</p>

<p>This diagram confirms the large-scale structure of the kernel
as outlined earlier. It is interesting to note that very few
developers worked on more than one system; where this did occur,
it occurred mainly where there is a subsystem dependency. The
organization supports the well-known rule of thumb stated by
Melvin Conway (see <a href="#Ref_NHD">[Raymond 1993]</a>) that
system organization often reflects developer organization. Most
of the developers worked on hardware device drivers, logical file
system modules, network device drivers, and network protocol
modules. It's not surprising that these four areas of the kernel
have been architected to support extensibility the most. </p>

<h2><a name="Toc_2_5">2.5 System Data Structures</a></h2>

<h3>2.5.1 Task List</h3>

<p>The process scheduler maintains a block of data for each
process that is active. These blocks of data are stored in a
linked list called the task list; the process scheduler always
maintains a <font face="Courier New">current</font> pointer that
indicates the current process that is active.</p>

<h3>2.5.2 Memory Map</h3>

<p>The memory manager stores a mapping of virtual to physical
addresses on a per-process basis, and also stores additional
information on how to fetch and replace particular pages. This
information is stored in a memory-map data structure that is
stored in the process scheduler's task list.</p>

<h3>2.5.3 I-nodes</h3>

<p>The Virtual File System uses index-nodes (i-nodes) to
represent files on a logical file system. The i-node data
structure stores the mapping of file block numbers to physical
device addresses. I-node data structures can be shared across
processes if two processes have the same file open. This sharing
is accomplished by both task data blocks pointing to the same
i-node.</p>

<h3>2.5.4 Data Connection</h3>

<p>All of the data structures are rooted at the task list of the
process scheduler. Each process on the system has a data
structure containing a pointer to its memory mapping information,
and also pointers to the i-nodes representing all of the opened
files. Finally, the task data structure also contains pointers to
data structures representing all of the opened network
connections associated with each task.</p>

<p>&nbsp;</p>

<hr size="1" noshade>

<h1><a name="Toc_3">3. Subsystem Architectures</a></h1>

<h2><a name="Toc_3_1">3.1 Process Scheduler Architecture</a></h2>

<h3>3.1.1 Goals</h3>

<p>The process scheduler is the most important subsystem in the
Linux kernel. Its purpose is to control access to the computer's
CPU(s). This includes not only access by user processes, but also
access for other kernel subsystems. </p>

<h3>3.1.2 Modules</h3>

<p>The scheduler is divided into four main modules:</p>

<ol>
    <li>The scheduling policy module is responsible for judging
        which process will have access to the CPU; the policy is
        designed so that processes will have fair access to the
        CPU.</li>
    <li>Architecture-specific modules are designed with a common
        interface to abstract the details of any particular
        computer architecture. These modules are responsible for
        communicating with a CPU to suspend and resume a process.
        These operations involve knowing what registers and state
        information need to be preserved for each process and
        executing the assembly code to effect a suspend or resume
        operation.</li>
    <li>The architecture-independent module communicates with the
        policy module to determine which process will execute
        next, then calls the architecture-specific module to
        resume the appropriate process. In addition, this module
        calls the memory manager to ensure that the memory
        hardware is restored properly for the resumed process.</li>
</ol>

<p>The system call interface module permits user processes access
to only those resources that are explicitly exported by the
kernel. This limits the dependency of user processes on the
kernel to a well-defined interface that rarely changes, despite
changes in the implementation of other kernel modules.</p>
<div align="center"><center>

<table border="0" cellpadding="3">
    <tr>
        <td align="center"><a name="Fig_Scheduler"><img
        src="scheduler.gif" width="640" height="340"></a></td>
    </tr>
    <tr>
        <td align="center"><strong>Figure 3.1: </strong><em>Process
        Scheduler</em><em><strong> </strong></em><em>Subsystem</em><em><strong>
        </strong></em><em>in Context</em></td>
    </tr>
</table>
</center></div>

<p>&nbsp;</p>

<h3>3.1.3 Data Representation</h3>

<p>The scheduler maintains a data structure, the task list, with
one entry for each active process. This data structure contains
enough information to suspend and resume the processes, but also
contains additional accounting and state information. This data
structure is publicly available throughout the kernel layer</p>

<h3>3.1.4 Dependencies, Data Flow, and Control Flow</h3>

<p>The process scheduler calls the memory manager subsystem as
mentioned earlier; because of this, the process scheduler
subsystem depends on the memory manager subsystem. In addition,
all of the other kernel subsystems depend on the process
scheduler to suspend and resume processes while waiting for
hardware requests to complete. These dependencies are expressed
through function calls and access to the shared task list data
structure. All kernel subsystems read and write the data
structure representing the current task, leading to
bi-directional data flow throughout the system.</p>

<p>In addition to the data and control flow within the kernel
layer, the O/S services layer provides an interface for user
processes to register for timer notification. This corresponds to
the implicit execution architectural style described in <a
href="#Ref_Garlan_1994">[Garlan 1994]</a>. This leads to a flow
of control from the scheduler to the user processes. The usual
case of resuming a dormant process is not considered a flow of
control in the normal sense because the user process cannot
detect this operation. Finally, the scheduler communicates with
the CPU to suspend and resume processes; this leads to a data
flow, and a flow of control. The CPU is responsible for
interrupting the currently executing process and allowing the
kernel to schedule another process.<a name="Sec_MMan"> </a></p>

<h2><a name="Toc_3_2">3.2 Memory Manager Architecture</a></h2>

<h3>3.2.1 Goals</h3>

<p>The memory manager subsystem is responsible for controlling
process access to the hardware memory resources. This is
accomplished through a hardware memory-management system that
provides a mapping between process memory references and the
machine's physical memory. The memory manager subsystem maintains
this mapping on a per process basis, so that two processes can
access the same virtual memory address and actually use different
physical memory locations. In addition, the memory manager
subsystem supports swapping; it moves unused memory pages to
persistent storage to allow the computer to support more virtual
memory than there is physical memory.</p>

<h3>3.2.2 Modules</h3>

<p>The memory manager subsystem is composed of three modules:</p>

<ol>
    <li>The architecture specific module presents a virtual
        interface to the memory management hardware</li>
    <li>The architecture independent manager performs all of the
        per-process mapping and virtual memory swapping. This
        module is responsible for determining which memory pages
        will be evicted when there is a page fault -- there is no
        separate policy module since it is not expected that this
        policy will need to change.</li>
    <li>A system call interface is provided to provide restricted
        access to user processes. This interface allows user
        processes to allocate and free storage, and also to
        perform memory mapped file I/O.</li>
</ol>

<h3>3.2.3 Data Representation</h3>

<p>The memory manager stores a per-process mapping of physical
addresses to virtual addresses. This mapping is stored as a
reference in the process scheduler's task list data structure. In
addition to this mapping, additional details in the data block
tell the memory manager how to fetch and store pages. For
example, executable code can use the executable image as a
backing store, but dynamically allocated data must be backed to
the system paging file. Finally, the memory manager stores
permissions and accounting information in this data structure to
ensure system security.</p>
<div align="center"><center>

<table border="0" cellpadding="3">
    <tr>
        <td align="center"><a name="Fig_MMAN"><img src="mman.gif"
        width="640" height="390"></a></td>
    </tr>
    <tr>
        <td align="center"><strong>Figure 3.2:</strong><em>
        Memory Manager subsystem in context</em></td>
    </tr>
</table>
</center></div>

<p>&nbsp;</p>

<h3>3.2.4 Data Flow, Control Flow, and Dependencies</h3>

<p>The memory manager controls the memory hardware, and receives
a notification from the hardware when a page fault occurs -- this
means that there is bi-directional data and control flow between
the memory manager modules and the memory manager hardware. Also,
the memory manager uses the file system to support swapping and
memory mapped I/O. This requirement means that the memory manager
needs to make procedure calls to the file system to store and
fetch memory pages from persistent storage. Because the file
system requests cannot be completed immediately, the memory
manager needs to suspend a process until the memory is swapped
back in; this requirement causes the memory manager to make
procedure calls into the process scheduler. Also, since the
memory mapping for each process is stored in the process
scheduler's data structures, there is a bi-directional data flow
between the memory manager and the process scheduler. User
processes can set up new memory mappings within the process
address space, and can register themselves for notification of
page faults within the newly mapped areas. This introduces a
control flow from the memory manager, through the system call
interface module, to the user processes. There is no data flow
from user processes in the traditional sense, but user processes
can retrieve some information from the memory manager using
select system calls in the system call interface module.</p>

<h2><a name="Toc_3_3">3.3 Virtual File System Architecture</a></h2>
<div align="center"><center>

<table border="0" cellpadding="3">
    <tr>
        <td align="center"><a name="Fig_VFS"><img src="vfs.gif"
        width="640" height="504"></a></td>
    </tr>
    <tr>
        <td align="center"><strong>Figure 3.3:</strong><em>
        Virtual File System in Context</em></td>
    </tr>
</table>
</center></div>

<p>&nbsp;</p>

<h3>3.3.1 Goals</h3>

<p>The virtual file system is designed to present a consistent
view of data as stored on hardware devices. Almost all hardware
devices in a computer are represented using a generic device
driver interface. The virtual file system goes further, and
allows the system administrator to mount any of a set of logical
file systems on any physical device. Logical file systems promote
compatibility with other operating system standards, and permit
developers to implement file systems with different policies. The
virtual file system abstracts the details of both physical device
and logical file system, and allows user processes to access
files using a common interface, without necessarily knowing what
physical or logical system the file resides on.</p>

<p>In addition to traditional file-system goals, the virtual file
system is also responsible for loading new executable programs.
This responsibility is accomplished by the logical file system
module, and this allows Linux to support several executable
formats.</p>

<h3>3.3.2 Modules</h3>

<ol>
    <li>There is one device driver module for each supported
        hardware controller. Since there are a large number of
        incompatible hardware devices, there are a large number
        of device drivers. The most common extension of a Linux
        system is the addition of a new device driver.</li>
    <li>The Device Independent Interface module provides a
        consistent view of all devices.</li>
    <li>There is one logical file system module for each
        supported file system.</li>
    <li>The system independent interface presents a hardware and
        logical-file-system independent view of the hardware
        resources. This module presents all resources using
        either a block-oriented or character-oriented file
        interface.</li>
    <li>Finally, the system call interface provides controlled
        access to the file system for user processes. The virtual
        file system exports only specific functionality to user
        processes.</li>
</ol>

<h3>3.3.3 Data Representation</h3>

<p>All files are represented using i-nodes. Each i-node structure
contains location information for specifying where on the
physical device the file blocks are. In addition, the i-node
stores pointers to routines in the logical file system module and
device driver that will perform required read and write
operations. By storing function pointers in this fashion, logical
file systems and device drivers can register themselves with the
kernel without having the kernel depend on any specific module.</p>

<h3>3.3.4 Data Flow, Control Flow, and Dependencies</h3>

<p>One specific device driver is a ramdisk; this device allocates
an area of main memory and treats it as a persistent-storage
device. This device driver uses the memory manager to accomplish
its tasks, and thus there is a dependency, control flow, and data
flow between the file system device drivers and the memory
manager.</p>

<p>One of the specific logical file systems that is supported is
the network file system (as a client only). This file system
accesses files on another machine as if they were part of the
local machine. To accomplish this, one of the logical file system
modules uses the network subsystem to complete its tasks. This
introduces a dependency, control flow, and data flow between the
two subsystems.</p>

<p>As mentioned in section 3.2, the memory manager uses the
virtual file system to accomplish memory swapping and
memory-mapped I/O. Also, the virtual file system uses the process
scheduler to disable processes while waiting for hardware
requests to complete, and resume them once the request has been
completed. Finally, the system call interface allows user
processes to call in to the virtual file system to store or
retrieve data. Unlike the previous subsystems, there is no
mechanism for users to register for implicit invocation, so there
is no control flow from the virtual file system towards user
processes (resuming processes is not considered control flow).</p>

<h2><a name="Toc_3_4">3.4 Network Interface Architecture</a></h2>

<h3>3.4.1 Goals</h3>

<p>The network subsystem allows Linux systems to connect to other
systems over a network. There are a number of possible hardware
devices that are supported, and a number of network protocols
that can be used. The network subsystem abstracts both of these
implementation details so that user processes and other kernel
subsystems can access the network without necessarily knowing
what physical devices or protocol is being used.</p>

<h3>3.4.2 Modules</h3>

<ol>
    <li>Network device drivers communicate with the hardware
        devices. There is one device driver module for each
        possible hardware device.</li>
    <li>The device independent interface module provides a
        consistent view of all of the hardware devices so that
        higher levels in the subsystem don't need specific
        knowledge of the hardware in use.</li>
    <li>The network protocol modules are responsible for
        implementing each of the possible network transport
        protocols.</li>
    <li>The protocol independent interface module provides an
        interface that is independent of hardware devices and
        network protocol. This is the interface module that is
        used by other kernel subsystems to access the network
        without having a dependency on particular protocols or
        hardware.</li>
</ol>

<p>Finally, the system calls interface module restricts the
exported routines that user processes can access.</p>
<div align="center"><center>

<table border="0" cellpadding="3">
    <tr>
        <td align="center"><a name="Fig_Net"><img src="net.gif"
        width="640" height="504"></a></td>
    </tr>
    <tr>
        <td align="center"><strong>Figure 3.4:</strong><em>
        Network Interface Subsystem in Context</em></td>
    </tr>
</table>
</center></div>

<p>&nbsp;</p>

<h3>3.4.3 Data Representation</h3>

<p>Each network object is represented as a socket. Sockets are
associated with processes in the same way that i-nodes are
associated; sockets can be share amongst processes by having both
of the task data structures pointing to the same socket data
structure. </p>

<h3>3.4.4 Data Flow, Control Flow, and Dependencies</h3>

<p>The network subsystem uses the process scheduler to suspend
and resume processes while waiting for hardware requests to
complete (leading to a subsystem dependency and control and data
flow). In addition, the network subsystem supplies the virtual
file system with the implementation of a logical file system
(NFS) leading to the virtual file system depending on the network
interface and having data and control flow with it. </p>

<h2><a name="Toc_3_5">3.5 Inter-Process Communication
Architecture</a></h2>

<p>The architecture of the inter-process communication subsystem
is omitted for brevity since it is not as interesting as the
other subsystems.</p>

<p>&nbsp;</p>

<hr size="1" noshade>

<h1><a name="Toc_4">4. Conclusions</a></h1>

<p>The Linux kernel is one layer in the architecture of the
entire Linux system. The kernel is conceptually composed of five
major subsystems: the process scheduler, the memory manager, the
virtual file system, the network interface, and the inter-process
communication interface. These subsystems interact with each
other using function calls and shared data structures.</p>

<p>At the highest level, the architectural style of the Linux
kernel is closes to Garlan and Shaw's <em>Data Abstraction</em>
style (<a href="#Ref_Garlan_1994">[Garlan1994]</a>); the kernel
is composed of subsystems that maintain internal representation
consistency by using a specific procedural interface. As each of
the subsystems is elaborated, we see an architectural style that
is similar to the <i>layered</i> style presented by Garlan and
Shaw. Each of the subsystems is composed of modules that
communicate only with adjacent layers.</p>

<p>The conceptual architecture of the Linux kernel has proved its
success; essential factors for this success were the provision
for the organization of developers, and the provision for system
extensibility. The Linux kernel architecture was required to
support a large number of independent volunteer developers. This
requirement suggested that the system portions that require the
most development -- the hardware device drivers and the file and
network protocols -- be implemented in an extensible fashion. The
Linux architect chose to make these systems be extensible using a
data abstraction technique: each hardware device driver is
implemented as a separate module that supports a common
interface. In this way, a single developer can add a new device
driver, with minimal interaction required with other developers
of the Linux kernel. The success of the kernel implementation by
a large number of volunteer developers proves the correctness of
this strategy.</p>

<p>Another important extension to the Linux kernel is the
addition of more supported hardware platforms. The architecture
of the system supports this extensibility by separating all
hardware-specific code into distinct modules within each
subsystem. In this way, a small group of developers can effect a
port of the Linux kernel to a new hardware architecture by
re-implementing only the machine-specific portions of the kernel.</p>

<p>&nbsp;</p>

<hr size="1" noshade>

<h1><a name="Toc_Definition">Definition of Terms</a></h1>

<dl>
    <dt><a name="Def_Device_Driver"><strong>Device Driver</strong></a></dt>
    <dd>A device driver is all of the code that is required to
        interface with a particular hardware device. Device
        drivers are properly part of the kernel, but the Linux
        kernel has a mechanism that permits dynamic loading of
        device drivers.</dd>
    <dt>&nbsp;</dt>
    <dt><a name="Dev_INode"><b>I-Node</b></a></dt>
    <dd>I-nodes, or index nodes, are used by the file system to
        keep track of which hardware addresses correspond to
        which file system data blocks. Each i-node stores a
        mapping of file block to physical block, plus additional
        information for security and accounting purposes.</dd>
    <dt>&nbsp;</dt>
    <dt><a name="Def_NFS"><strong>Network File System (NFS)</strong></a></dt>
    <dd>The Network File System is a file system interface that
        presents files that are stored on a remote computer as a
        file system on the local machine.</dd>
    <dt>&nbsp;</dt>
    <dt><a name="Def_Process"><strong>Process</strong></a></dt>
    <dd>A process (also called a task) is a program in execution;
        it consists of executable code and dynamic data. The
        kernel associates enough information with each process to
        stop and resume it.</dd>
    <dt>&nbsp;</dt>
    <dt><a name="Def_Ramdisk"><strong>Ramdisk</strong></a></dt>
    <dd>A ramdisk is a device drive that uses an area of main
        memory as a file system device. This allows frequently
        accessed files to be placed in an area that provides
        reliably efficient access at all times; this can be
        especially useful when using Linux to support hard
        real-time requirements. For usual cases, the normal file
        system caching will make the most efficient use of memory
        to provide reasonably efficient access to files.</dd>
    <dt>&nbsp;</dt>
    <dt><a name="Def_Swapping"><strong>Swapping</strong></a></dt>
    <dd>Linux supports processes that use memory that exceeds the
        amount of physical memory on the computer. This is
        accomplished by the memory manager swapping unused pages
        of memory to a persistent store; when the memory is later
        accessed, it is swapped back into the main memory
        (possibly causing other pages to be swapped out).</dd>
    <dt>&nbsp;</dt>
    <dt><a name="Def_Task"><strong>Task</strong></a></dt>
    <dd>See Process</dd>
</dl>

<p>&nbsp;</p>

<hr size="1" noshade>

<h1><a name="Toc_References">References</a></h1>

<dl>
    <dt><a name="Ref_Garlan_1994"><strong>[Garlan 1994]</strong></a></dt>
    <dd><a href="http://www.cs.cmu.edu/~garlan/">David Garlan</a>
        and <a href="http://www.cs.cmu.edu/~shaw/">Mary Shaw</a>,
        <a
        href="http://www.cs.cmu.edu/afs/cs/project/able/www/paper_abstracts/intro_softarch.html">An
        Introduction to Software Architecture</a>, Advances in
        Software Engineering and Knowledge Engineering, Volume I,
        World Scientific Publishing Company, 1993.</dd>
    <dt>&nbsp;</dt>
    <dt><a name="Ref_Monroe_1997"><b>[Monroe 1997]</b></a></dt>
    <dd><a href="http://www.cs.cmu.edu/~bmonroe/">Robert T.
        Monroe</a>, <a href="http://www.cs.cmu.edu/~kompanek/">Andrew
        Kompanek</a>, <a href="http://www.cs.cmu.edu/~ralph/">Ralph
        Melton</a>, and <a href="http://www.cs.cmu.edu/~garlan/">David
        Garlan</a>, <a
        href="http://pecan.srv.cs.cmu.edu/afs/cs/project/able/www/paper_abstracts/ObjPatternsArch-ieee.html">Architectural
        Styles, Design Patterns, and Objects</a>, IEEE Software,
        January 1997, pp 43-52. </dd>
    <dt>&nbsp;</dt>
    <dt><a name="Ref_Parker_1997"><strong>[Parker 1997]</strong></a></dt>
    <dd><em>Slackware Linux Unleashed</em>, by Timothy Parker, et
        al, Sams Publishing, 201 West 103rd Street, Indianapolis.</dd>
    <dt>&nbsp;</dt>
    <dt><a name="Ref_Perry_1992"><b>[Perry 1992]</b></a></dt>
    <dd><a href="http://www.bell-labs.com/user/dep/">Dewayne E.
        Perry</a> and <a
        href="http://www.cs.colorado.edu/~alw/Home.html">Alexander
        L. Wolf</a>, <a
        href="http://www.bell-labs.com/user/dep/work/swa/">Foundations
        for the Study of Software Architecture</a>, ACM SIGSOFT
        Software Engineering Notes, 17:4, October 1992 pp 40-52.</dd>
    <dt>&nbsp;</dt>
    <dt><a name="Ref_NHD"><b>[Raymond 1993]</b></a></dt>
    <dd><i>The New Hackers Dictionary</i>, Second Edition,
        compiled by Eric S. Raymond. The MIT Press, Cambridge
        Massachusetts, 1993.</dd>
    <dt>&nbsp;</dt>
    <dt><a name="Ref_Rusling_1997"><b>[Rusling 1997]</b></a></dt>
    <dd><i>The Linux Kernel</i>, by <a
        href="mailto:David.Rusling@reo.mts.dec.com">David A.
        Rusling</a>, draft, version 0.1-13(19), <a
        href="ftp://sunsite.unc.edu/pub/Linux/docs/linux-doc-project/linux-kernel/">ftp://sunsite.unc.edu/pub/Linux/docs/linux-doc-project/linux-kernel/</a>
        or <a href="http://www.linuxhq.com/guides/TLK/index.html">http://www.linuxhq.com/guides/TLK/index.html</a>.</dd>
    <dt>&nbsp;</dt>
    <dt><a name="Ref_Soni_1995"><b>[Soni 1995]</b></a></dt>
    <dd>Soni, D.; Nord, R. L.; Hofmeister, C., Software
        Architecture in Industrial Applications, IEEE ICSE 1995,
        pp. 196-210.</dd>
    <dd>&nbsp;</dd>
    <dt><strong>[Tanenbaum 1992]</strong></dt>
    <dd><em>Modern Operating Systems</em>, by Andrew S.
        Tanenbaum, Prentice Hall, 1992.</dd>
    <dt>&nbsp;</dt>
    <dt><a name="Ref_Wirzenius_1997"><b>[Wirzenius 1997]</b></a></dt>
    <dd><i>Linux System Administrators' Guide 0.6</i>, by Lars
        Wirzenius, <a href="http://www.iki.fi/liw/linux/sag/">http://www.iki.fi/liw/linux/sag/</a>
        or <a
        href="http://www.linuxhq.com/LDP/LDP/sag/index.html">http://www.linuxhq.com/LDP/LDP/sag/index.html</a>.</dd>
</dl>
</body>
</html>
