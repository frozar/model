<HTML>
<HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=windows-1251">
<TITLE>Chapter 18. TCP Connection Establishment and Termination
</TITLE>

<META NAME="GENERATOR" CONTENT="Internet Assistant for Microsoft Word 2.04z">
</HEAD>
<BODY>
<a name="18_0"><H1><I>TCP Connection Establishment and Termination</I></H1></a>
<a name="18_1"><H3>18.1 Introduction</H3></a>
<P>
TCP is a <I>connection-oriented</I> protocol. Before
either end can send data to the other, a <I>connection</I> must
be established between them. In this chapter we take a detailed
look at how a TCP connection is established and later terminated.
<P>
This establishment of a connection between the two
ends differs from a <I>connectionless</I> protocol such as UDP.
We saw in <a href="udp_user.htm#11_0" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/udp_user.htm#11_0">Chapter 11</a> that with UDP one end just sends a datagram
to the other end, without any preliminary handshaking.
<a name="18_2"><H3>18.2 Connection Establishment and Termination</H3></a>
<P>
To see what happens when a TCP connection is established
and then terminated, we type the following command on the system
<TT>svr4</TT>:
<TABLE>
<TR><TD WIDTH=280><TT>svr4 % <B>telnet bsdi discard</B></TT>
</TD><TD WIDTH=380></TD></TR>
<TR><TD WIDTH=280><TT>Trying 192.82.148.3 ...</TT></TD><TD WIDTH=380>
</TD></TR>
<TR><TD WIDTH=280><TT>Connected to bsdi.</TT></TD><TD WIDTH=380>
</TD></TR>
<TR><TD WIDTH=280><TT>Escape character is '^]'.</TT></TD><TD WIDTH=380>
</TD></TR>
<TR><TD WIDTH=280><TT><B>^]</B></TT>
</TD><TD WIDTH=380><I>type Control, right bracket to talk to the Telnet client</I>
</TD></TR>
<TR><TD WIDTH=280><TT>telnet&gt; <B>quit</B></TT>
</TD><TD WIDTH=380><I>terminate the connection</I>
</TD></TR>
<TR><TD WIDTH=280><TT>Connection closed.</TT></TD><TD WIDTH=380>
</TD></TR>
</TABLE>
<P>
The <TT>telnet</TT> command establishes
a TCP connection with the host <TT>bsdi</TT>
on the port corresponding to the discard service (<a href="introduc.htm#1_12" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/introduc.htm#1_12">Section 1.12</a>).
This is exactly the type of service we need to see what happens
when a connection is established and terminated, without having
the server initiate any data exchange.
<H4><TT>tcpdump</TT> Output</H4>
<P>
Figure 18.1 shows the <TT>tcpdump</TT>
output for the segments generated by this command.
<CENTER>
<a name="fig_18_1"><TABLE></a>
<TR><TD WIDTH=26>1</TD><TD WIDTH=200><TT>0.0</TT>
</TD><TD WIDTH=525><TT>svr4.1037 &gt; bsdi.discard: S 1415531521:1415531521(0)
<BR>
win 4096 &lt;mss 1024&gt;</TT>
</TD></TR>
<TR><TD WIDTH=26>2</TD><TD WIDTH=200><TT>0.002402 (0.0024)</TT>
</TD><TD WIDTH=525><TT>bsdi.discard &gt; svr4.1037: S 1823083521:1823083521(0)
<BR>
ack 1415531522 win 4096 &lt;mss 1024&gt;</TT>
</TD></TR>
<TR><TD WIDTH=26>3</TD><TD WIDTH=200><TT>0.007224 (0.0048)</TT>
</TD><TD WIDTH=525><TT>svr4.1037 &gt; bsdi.discard: ack 1823083522 win 4096</TT>
</TD></TR>
<TR><TD WIDTH=26>4</TD><TD WIDTH=200><TT>4.155441 (4.1482)</TT>
</TD><TD WIDTH=525><TT>svr4.1037 &gt; bsdi.discard: F 1415531522:1415531522(0)
<BR>
ack 1823083522 win 4096 </TT>
</TD></TR>
<TR><TD WIDTH=26>5</TD><TD WIDTH=200><TT>4.156747 (0.0013)</TT>
</TD><TD WIDTH=525><TT>bsdi.discard &gt; svr4.1037: . ack 1415531523 win 4096</TT>
</TD></TR>
<TR><TD WIDTH=26>6</TD><TD WIDTH=200><TT>4.158144 (0.0014)</TT>
</TD><TD WIDTH=525><TT>bsdi.discard &gt; svr4.1037: F 1823083522:1823083522(0)
<BR>
ack 1415531523 win 4096</TT>
</TD></TR>
<TR><TD WIDTH=26>7</TD><TD WIDTH=200><TT>4.180662 (0.0225)</TT>
</TD><TD WIDTH=525><TT>svr4.1037 &gt; bsdi.discard: . ack 1823083523 win 4096</TT>
</TD></TR>
</TABLE>
</CENTER>
<P>
<CENTER><B>Figure 18.1</B> <TT>tcpdump</TT>
output for TCP connection establishment and termination.</CENTER>
<P>
These seven TCP segments contain TCP headers only.
No data is exchanged. For TCP segments, each output line begins
with
<P>
<I>source &gt; destination: flags</I>
<P>
where <I>flags</I> represents four of the six flag
bits in the TCP header (<a href="tcp_tran.htm#fig_17_2" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/tcp_tran.htm#fig_17_2">Figure 17.2</a>). Figure 18.2 shows the five
different characters that can appear in <I>the flags</I> output.
<P>
<CENTER>
<a name="fig_18_2"><TABLE BORDER=1></a>
<TR><TD WIDTH=34><CENTER><I>flag</I></CENTER>
</TD><TD WIDTH=75><CENTER>3-character abbreviation</CENTER>
</TD><TD WIDTH=430>Description</TD></TR>
<TR><TD WIDTH=34><CENTER>S<BR>
F<BR>
R<BR>
P<BR>
.</CENTER>
</TD><TD WIDTH=75><CENTER>SYN<BR>
FIN<BR>
RST<BR>
PSH<BR>-</CENTER>
</TD><TD WIDTH=430>synchronize sequence numbers<BR>
sender is finished sending data<BR>
reset connection<BR>
push data to receiving process as soon as possible<BR>
none of above four flags is on
</TD></TR>
</TABLE>
</CENTER>
<P>
<CENTER><B>Figure 18.2</B> <I>flag</I>
characters output by <TT>tcpdump</TT> for
flag bits in TCP header.</CENTER>
<P>
In this example we see the <TT>S</TT>,
<TT>F</TT>, and period. We'll see the other
<I>two flags</I> (<TT>R</TT> and <TT>P</TT>)
later. The other two TCP header flag bits-ACK and URG-are printed
specially by <TT>tcpdump</TT>.
<P>
It's possible for more than one of the four flag
bits in Figure 18.2 to be on in a single segment, but we normally
see only one on at a time.
<P>
<FONT SIZE=-1>RFC 1025 [Postel 1987], the <I>TCP and IP Bake Off,</I>
calls a segment with the maximum combination of allowable flag
bits turned on at once (SYN, URG, PSH, FIN, and 1 byte of data)
a Kamikaze packet. It's also known as a nastygram, Christmas tree
packet, and lamp test segment.</FONT>
<P>
In line 1, the field <TT>1415531521:1415531521</TT>
(0) means the sequence number of the packet was 1415531521 and
the number of data bytes in the segment was 0. <TT>tcpdump</TT>
displays this by printing the starting sequence number, a colon,
the implied ending sequence number, and the number of data bytes
in parentheses. The advantage of displaying both the sequence
number and the implied ending sequence number is to see what the
implied ending sequence number is, when the number of bytes is
greater than 0. This field is output only if (1) the segment contains
one or more bytes of data or (2) the SYN, FIN, or RST flag was
on. Lines 1, 2,
4, and 6 in <a href="#fig_18_1">Figure 18.1</a> display this field
because of the flag bits-we never exchange any data in this example.
<P>
In line 2 the field <TT>ack 1415531522</TT>
shows the acknowledgment number. This is printed only if the ACK
flag in the header is on.
<P>
The field <TT>win 4096</TT> in
every line of output shows the window size being advertised by
the sender. In these examples, where we are not exchanging any
data, the window size never changes from its default of 4096.
(We examine TCP's window size in <a href="tcp_bulk.htm#20_4" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/tcp_bulk.htm#20_4">Section 20.4</a>.)
<P>
The final field that is output in <a href="#fig_18_1">Figure 18.1</a>, <TT>&lt;mss
1024&gt;</TT> shows the <I>maximum segment size</I>
(MSS) option specified by the sender. The sender does not want
to receive TCP segments larger than this value. This is normally
to avoid fragmentation (<a href="udp_user.htm#11_5" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/udp_user.htm#11_5">Section 11.5</a>). We discuss the maximum
segment size in <a href="#18_4">Section 18.4</a>, and show the format of the various
TCP options in <a href="#18_10">Section 18.10</a>.
<H4>Time Line</H4>
<P>
<a href="#fig_18_3">Figure 18.3</a> shows the time line for this sequence
of packets. (We described some general features of these time
lines when we showed the first one in <a href="icmp_int.htm#fig_6_11" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/icmp_int.htm#fig_6_11">Figure 6.11</a>.) This figure
shows which end is sending packets. We also expand some of the
<TT>tcpdump</TT> output (e.g., printing SYN
instead of <TT>S</TT>). In this time line
we have also removed the window size values, since they add nothing
to the discussion.
<H4>Connection Establishment Protocol</H4>
<P>
Now let's return to the details of the TCP protocol
that are shown in Figure 18.3. To establish a TCP connection:
<OL>
<LI>The requesting end (normally called the <I>client)</I>
sends a SYN segment specifying the port number of the <I>server</I>
that the client wants to connect to, and the client's <I>initial
sequence number</I> (ISN, 1415531521 in this example). This is
segment 1.
<LI>The server responds with its own SYN segment
containing the server's initial sequence number (segment 2). The
server also acknowledges the client's SYN by ACKing the client's
ISN plus one. A SYN consumes one sequence number.
<LI>The client must acknowledge this SYN from the
server by ACKing the server's ISN plus one (segment 3).
</OL>
<P>
These three segments complete the connection establishment.
This is often called the <I>three-way handshake.
</I>
<P>
<CENTER><a name="fig_18_3"><img src="f_18_3.gif" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/gifs/f_18_3.gif"></a><br>
<B>Figure 18.3</B> Time
line of connection establishment and connection termination.</CENTER>
<P>
The side that sends the first SYN is said to perform
an <I>active open.</I> The other side, which receives this SYN
and sends the next SYN, performs a <I>passive open.</I> (In <a href="#18_8">Section 18.8</a>
we describe a simultaneous open where both sides can do an
active open.)
<P>
When each end sends its SYN to establish the connection,
it chooses an initial sequence number for that connection. The
ISN should change over time, so that each connection has a different
ISN. RFC 793 [Postel 1981c] specifies that the ISN should be viewed
as a 32-bit counter that increments by one every 4 microseconds.
The purpose in these sequence numbers is to prevent packets that
get delayed in the network from being delivered later and then
misinterpreted as part of an existing connection.
<P>
<FONT SIZE=-1>How are the sequence numbers chosen? In 4.4BSD (and
most Berkeley-derived implementations) when the system is initialized
the initial send sequence number is initialized to 1. This practice
violates the Host Requirements RFC. (A comment in the code acknowledges
that this is wrong.) This variable is then incremented by 64,000
every half-second, and will cycle back to 0 about every 9.5 hours.
(This corresponds to a counter that is incremented every 8 microseconds,
not every 4 microseconds.) Additionally, each time a connection
is established, this variable is incremented by 64,000.</FONT>
<P>
The 4.1-second gap between segments 3 and 4 is the
time between establishing the connection and typing the <TT>quit</TT>
command to <TT>telnet</TT> to terminate the
connection.
<H4>Connection Termination Protocol</H4>
<P>
While it takes three segments to establish a connection,
it takes four to terminate a connection. This is caused by TCP's
<I>half-close.</I> Since a TCP connection is full-duplex (that
is, data can be flowing in each direction independently of the
other direction), each direction must be shut down independently.
The rule is that either end can send a FIN when it is done sending
data. When a TCP receives a FIN, it must notify the application
that the other end has terminated that direction of data flow.
The sending of a FIN is normally the result of the application
issuing a close.
<P>
The receipt of a FIN only means there will be no
more data flowing in that direction. A TCP can still send data
after receiving a FIN. While it's possible for an application
to take advantage of this half-close, in practice few TCP applications
use it. The normal scenario is what we show in <a href="#fig_18_3">Figure 18.3</a>. We
describe the half-close in more detail in <a href="#18_5">Section 18.5</a>.
<P>
We say that the end that first issues the close (e.g.,
sends the first FIN) performs the <I>active close</I> and the
other end (that receives this FIN) performs the <I>passive close.</I>
Normally one end does the active close and the other does the
passive close, but we'll see in <a href="#18_9">Section 18.9</a> how both ends can
do an active close.
<P>
Segment 4 in <a href="#fig_18_3">Figure 18.3</a> initiates the termination
of the connection and is sent when the Telnet client closes its
connection. This happens when we type <TT>quit</TT>.
This causes the client TCP to send a FIN, closing the flow of
data from the client to the server.
<P>
When the server receives the FIN it sends back an
ACK of the received sequence number plus one (segment 5). A FIN
consumes a sequence number, just like a SYN. At this point the
server's TCP also delivers an end-of-file to the application (the
discard server). The server then closes its connection, causing
its TCP to send a FIN (segment 6), which the client TCP must ACK
by incrementing the received sequence number by one (segment 7).
<P>
Figure 18.4 shows the typical sequence of segments
that we've described for the termination of a connection. We omit
the sequence numbers. In this figure sending the FINs is caused
by the applications closing their end of the connection, whereas
the ACKs of these FINs are automatically generated by the TCP
software.
<P>
Connections are normally initiated by the client,
with the first SYN going from the client to the server. Either
end can actively close the connection (i.e., send the first FIN).
Often, however, it is the client that determines when the connection
should be terminated, since client processes are often driven
by an interactive user, who enters something like &quot;quit&quot;
to terminate. In Figure 18.4 we can switch the labels at the top,
calling the left side the server and the right side the client,
and everything still works fine as shown. (The first example in
<a href="dns_the.htm#14_4" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/dns_the.htm#14_4">Section 14.4</a>, for example, shows the daytime server closing the
connection.)

<P>
<CENTER><a name="fig_18_4"><img src="f_18_4.gif" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/gifs/f_18_4.gif"></a><br>
<B>Figure 18.4</B> Normal
exchange of segments during connection termination.</CENTER>
<H4>Normal <TT>tcpdump</TT> Output</H4>
<P>
Having to sort through all the huge sequence numbers
is cumbersome, so the default <TT>tcpdump</TT>
output shows the complete sequence numbers only on the SYN segments,
and shows all following sequence numbers as relative offsets from
the original sequence numbers. (To generate the output for <a href="#fig_18_1">Figure 18.1</a>
we had to specify the <TT>-S</TT> option.)
The normal <TT>tcpdump</TT> output corresponding
to <a href="#fig_18_1">Figure 18.1</a> is shown in Figure 18.5.
<P>
<CENTER>
<a name="fig_18_5"><TABLE></a>
<TR><TD WIDTH=26>1</TD><TD WIDTH=200><TT>0.0</TT>
</TD><TD WIDTH=525><TT>svr4.1037 &gt; bsdi.discard: S 1415531521:1415531521(0)
<BR>
win 4096 &lt;mss 1024&gt;</TT>
</TD></TR>
<TR><TD WIDTH=26>2</TD><TD WIDTH=200><TT>0.002402 (0.0024)</TT>
</TD><TD WIDTH=525><TT>bsdi.discard &gt; svr4.1037: S 1823083521:1823083521(0)
<BR>
ack 1415531522 win 4096 &lt;mss 1024&gt;</TT>
</TD></TR>
<TR><TD WIDTH=26>3</TD><TD WIDTH=200><TT>0.007224 (0.0048)</TT>
</TD><TD WIDTH=525><TT>svr4.1037 &gt; bsdi.discard: . ack 1 win 4096</TT>
</TD></TR>
<TR><TD WIDTH=26>4</TD><TD WIDTH=200><TT>4.155441 (4.1482)</TT>
</TD><TD WIDTH=525><TT>svr4.1037 &gt; bsdi.discard: F 1:1(0) ack 1 win 4096</TT>
</TD></TR>
<TR><TD WIDTH=26>5</TD><TD WIDTH=200><TT>4.156747 (0.0013)</TT>
</TD><TD WIDTH=525><TT>bsdi.discard &gt; svr4.1037: . ack 2 win 4096</TT>
</TD></TR>
<TR><TD WIDTH=26>6</TD><TD WIDTH=200><TT>4.158144 (0.0014)</TT>
</TD><TD WIDTH=525><TT>bsdi.discard &gt; svr4.1037: F 1:1(0) ack 2 win 4096</TT>
</TD></TR>
<TR><TD WIDTH=26>7</TD><TD WIDTH=200><TT>4.180662 (0.0225)</TT>
</TD><TD WIDTH=525><TT>svr4.1037 &gt; bsdi.discard: . ack 2 win 4096</TT>
</TD></TR>
</TABLE>
</CENTER><P>
<B>Figure 18.5</B> Normal <TT>tcpdump</TT>
output for connection establishment and termination.
<P>
Unless we need to show the complete sequence numbers,
we'll use this form of output in all following examples.
<a name="18_3"><H3>18.3 Timeout of Connection Establishment</H3></a>
<P>
There are several instances when the connection cannot
be established. In one example the server host is down. To simulate
this scenario we issue our <TT>telnet</TT>
command after disconnecting the Ethernet cable from the server's
host. Figure 18.6 shows the <TT>tcpdump</TT>
output.
<CENTER>
<a name="fig_18_6"><TABLE></a>
<TR><TD WIDTH=26>1</TD><TD WIDTH=200><TT>0.0</TT>
</TD><TD WIDTH=525><TT>bsdi-1024 &gt; svr4.discard: S 291008001:291008001(0)
<BR>
win 4096 &lt;mss 1024&gt; [tos 0x10]</TT>
</TD></TR>
<TR><TD WIDTH=26>2</TD><TD WIDTH=200><TT>5.814797 ( 5.8148)</TT>
</TD><TD WIDTH=525><TT>bsdi-1024 &gt; svr4.discard: S 291008001:291008001(0)
<BR>
win 4096 &lt;mss 1024&gt; [tos 0x10]</TT>
</TD></TR>
<TR><TD WIDTH=26>3</TD><TD WIDTH=200><TT>29.815436 (24.0006)</TT>
</TD><TD WIDTH=525><TT>bsdi.l024 &gt; svr4.discard: S 291008001:291008001(0)
<BR>
win 4096 &lt;mss 1024&gt; [tos 0x10]</TT>
</TD></TR>
</TABLE>
</CENTER><P>
<CENTER><B>Figure 18.6</B> <TT>tcpdump</TT>
output for connection establishment that times out.</CENTER>
<P>
The interesting point in this output is how frequently
the client's TCP sends a SYN to try to establish the connection.
The second segment is sent 5.8 seconds after the first, and the
third is sent 24 seconds after the second.
<P>
<FONT SIZE=-1>As a side note, this example was run about 38 minutes
after the client was rebooted. This corresponds with the initial
sequence number of 291,008,001 (approximately 38 x 60 x 64000
x 2). Recall earlier in this chapter we said that typical Berkeley-derived
systems initialize the initial sequence number to 1 and then increment
it by 64,000 every half-second.
<P>
Also, this is the first TCP connection since the
system was bootstrapped, which is why the client's port number
is 1024.</FONT>
<P>
What isn't shown in Figure 18.6 is how long the client's
TCP keeps retransmitting before giving up. To see this we have
to time the <TT>telnet</TT> command:
<P>
<TT>bsdi % <B>date ; telnet svr4 discard ; date<BR>
</B>Thu Sep 24 16:24:11 MST 1992<BR>
Trying 192.82.148.2...<BR>
telnet: Unable to connect to remote host: Connection timed out
<BR>
Thu Sep 24 16:25:27 MST 1992</TT>
<P>
The time difference is 76 seconds. Most Berkeley-derived
systems set a time limit of 75 seconds on the establishment of
a new connection. We'll see in <a href="tcp_time.htm#21_4" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/tcp_time.htm#21_4">Section 21.4</a> that the third packet
sent by the client would have timed out around 16:25:29, 48 seconds
after it was sent, had the client not given up after 75 seconds.
<H4>First Timeout Period</H4>
<P>
One puzzling item in <a href="#fig_18_6">Figure 18.6</a> is that the first
timeout period, 5.8 seconds, is close to 6 seconds, but not exact,
while the second period is almost exactly 24 seconds. Ten more
of these tests were run and the first timeout period took on various
values between 5.59 seconds and 5.93 seconds. The second timeout
period, however, was always 24.00 (to two decimal places).
<P>
What's happening here is that BSD implementations
of TCP run a timer that goes off every 500 ms. This 500-ms timer
is used for various TCP timeouts, all of which we cover in later
chapters. When we type in the <TT>telnet</TT>
command, an initial 6-second timer is established (12 clock ticks),
but it may expire anywhere between 5.5 and 6 seconds in the future.
Figure 18.7 shows what's happening.
<P>
<CENTER><a name="fig_18_7"><img src="f_18_7.gif" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/gifs/f_18_7.gif"></a><br>
<B>Figure 18.7</B> TCP
500-ms timer.</CENTER>
<P>
Although the timer is initialized to 12 ticks, the
first decrement of the timer can occur between 0 and 500 ms after
it is set. From that point on the timer is decremented about every
500 ms, but the first period can be variable. (We use the qualifier
&quot;about&quot; because the time when TCP gets control every
500 ms can be preempted by other interrupts being handled by the
kernel.)
<P>
When that 6-second timer expires at the tick labeled
0 in Figure 18.7, the timer is reset for 24 seconds (48 ticks)
in the future. This next timer will be close to 24 seconds, since
it was set at a time when the TCP's 500-ms timer handler was called
by the kernel.
<H4>Type-of-Service Field</H4>
<P>
In <a href="#fig_18_6">Figure 18.6</a>, the notation <TT>[tos 0x10]</TT>
appears. This is the type-of-service(TOS) field in the IP datagram
(<a href="ip_inter.htm#fig_3_2" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/ip_inter.htm#fig_3_2">Figure 3.2</a>). The BSD/386 Telnet client sets the field for minimum
delay.
<a name="18_4"><H3>18.4 Maximum Segment Size</H3></a>
<P>
The maximum segment size (MSS) is the largest &quot;chunk&quot;
of data that TCP will send to the other end. When a connection
is established, each end can announce its MSS. The values we've
seen have all been 1024. The resulting IP datagram is normally
40 bytes larger: 20 bytes for the TCP header and 20 bytes for
the IP header.
<P>
Some texts refer to this as a &quot;negotiated&quot;
option. It is not negotiated in any way. When a connection is
established, each end has the option of announcing the MSS it
expects to receive. (An MSS option can only appear in a SYN segment.)
If one end does not receive an MSS option from the other end,
a default of 536 bytes is assumed. (This default allows for a
20-byte IP header and a 20-byte TCP header to fit into a 576-byte
IP datagram.)
<P>
In general, the larger the MSS the better, until
fragmentation occurs. (This may not always be true. See <a href="tcp_fut.htm#fig_24_3" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/tcp_fut.htm#fig_24_3">Figures
24.3</a> and <a href="tcp_fut.htm#fig_24_4" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/tcp_fut.htm#fig_24_4">24.4</a> for a counterexample.) A larger segment size allows
more data to be sent in each segment, amortizing the cost of the
IP and TCP headers. When TCP sends a SYN segment, either because
a local application wants to initiate a connection, or when a
connection request is received from another host, it can send
an MSS value up to the outgoing interface's MTU, minus the size
of the fixed TCP and IP headers. For an Ethernet this implies
an MSS of up to 1460 bytes. Using IEEE 802.3 encapsulation (<a href="link_lay.htm#2_2" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/link_lay.htm#2_2">Section 2.2</a>),
the MSS could go up to 1452 bytes.
<P>
The values of 1024 that we've seen in this chapter,
for connections involving BSD/386 and SVR4, are because many BSD
implementations require the MSS to be a multiple of 512. Other
systems, such as SunOS 4.1.3, Solaris 2.2, and AIX 3.2.2, all
announce an MSS of 1460 when both ends are on a local Ethernet.
Measurements in [Mogul 1993] show how an MSS of 1460 provides
better performance on an Ethernet than an MSS of 1024.
<P>
If the destination IP address is &quot;nonlocal,&quot;
the MSS normally defaults to 536. While it's easy to say that
a destination whose IP address has the same network ID and the
same subnet ID as ours is local, and a destination whose IP address
has a totally different network ID from ours is nonlocal, a destination
with the same network ID but a different subnet ID could be either
local or nonlocal. Most implementations provide a configuration
option (<a href="append_e.htm" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/append_e.htm">Appendix E</a> and <a href="append_e.htm#fig_E_1" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/append_e.htm#fig_E_1">Figure E.1</a>)
that lets the system administrator
specify whether different subnets are local or nonlocal. The setting
of this option determines whether the announced MSS is as large
as possible (up to the outgoing interface's MTU) or the default
of 536.
<P>
The MSS lets a host limit the size of datagrams that
the other end sends it. When combined with the fact that a host
can also limit the size of the datagrams that it sends, this lets
a host avoid fragmentation when the host is connected to a network
with a small MTU.
<P>
Consider our host <TT>slip</TT>,
which has a SLIP link with an MTU of 296 to the router <TT>bsdi</TT>.
Figure 18.8 shows these systems and the host <TT>sun</TT>.

<P>
<CENTER><a name="fig_18_8"><img src="f_18_8.gif" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/gifs/f_18_8.gif"></a><br>
<B>Figure 18.8</B> TCP
connection from <TT>sun</TT> to <TT>slip</TT>
showing MSS values.</CENTER>
<P>
We initiate a TCP connection from <TT>sun</TT>
to <TT>slip</TT> and watch the segments using
<TT>tcpdump</TT>. Figure 18.9 shows only the
connection establishment (with the window size advertisements
removed).
<CENTER>
<a name="fig_18_9"><TABLE></a>
<TR><TD WIDTH=26>1</TD><TD WIDTH=180><TT>0.0</TT>
</TD><TD WIDTH=520><TT>sun.1093 &gt; slip.discard: S 517312000:517312000 (0)
<BR>
&lt;mss 1460&gt;</TT>
</TD></TR>
<TR><TD WIDTH=26>2</TD><TD WIDTH=180><TT>0.10 (0.00)</TT>
</TD><TD WIDTH=520><TT>slip.discard &gt; sun.1093: S 509556225:509556225 (0)<BR>
ack 517312001 &lt;mss 256&gt;</TT>
</TD></TR>
<TR><TD WIDTH=26>3</TD><TD WIDTH=180><TT>0.10 (0.00)</TT>
</TD><TD WIDTH=520><TT>sun.1093 &gt; slip.discard: . ack 1 </TT>
</TD></TR>
</TABLE>
</CENTER>
<P>
<CENTER>Figure 18.9 <TT>tcpdump</TT>
output for connection establishment from <TT>sun</TT>
to <TT>slip</TT>.</CENTER>
<P>
The important fact here is that <TT>sun</TT>
cannot send a segment with more than 256 bytes of data, since
it received an MSS option of 256 (line 2). Furthermore, since
<TT>slip</TT> knows that the outgoing interface's
MTU is 296, even though <TT>sun</TT> announced
an MSS of 1460, it will never send more than 256 bytes of data,
to avoid fragmentation. It's OK for a system to send <I>less</I>
than the MSS announced by the other end.
<P>
This avoidance of fragmentation works only if either
host is directly connected to a network with an MTU of less than
576. If both hosts are connected to Ethernets, and both announce
an MSS of 536, but an intermediate network has an MTU of 296,
fragmentation will occur. The only way around this is to use the
path MTU discovery mechanism (<a href="tcp_fut.htm#24_2" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/tcp_fut.htm#24_2">Section 24.2</a>).
<a name="18_5"><H3>18.5 TCP Half-Close</H3></a>
<P>
TCP provides the ability for one end of a connection
to terminate its output, while still receiving data from the other
end. This is called a <I>half-close.</I> Few applications take
advantage of this capability, as we mentioned earlier.
<P>
To use this feature the programming interface must
provide a way for the application to say &quot;I am done sending
data, so send an end-of-file (FIN) to the other end, but I still
want to receive data from the other end, until it sends me an
end-of-file (FIN).&quot;
<P>
<FONT SIZE=-1>The sockets API supports the half-close, if the application
calls shutdown with a second argument of 1, instead of calling
<TT>close</TT>. Most applications, however,
terminate both directions of the connection by calling <TT>close</TT>.</FONT>
<P>
Figure 18.10 shows a typical scenario for a half-close.
We show the client on the left side initiating the half-close,
but either end can do this. The first two segments are the same:
a FIN by the initiator, followed by an ACK of the FIN by the recipient.
But it then changes from Figure 18.4, because the side that receives
the half-close can still send data. We show only one data segment,
followed by an ACK, but any number of data segments can be sent.
(We talk more about the exchange of data segments and acknowledgments
in <a href="tcp_int.htm#19_0" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/tcp_int.htm#19_0">Chapter 19</a>.) When the end that received the half-close is done
sending data, it closes its end of the connection, causing a FIN
to be sent, and this delivers an end-of-file to the application
that initiated the half-close. When this second FIN is acknowledged,
the connection is completely closed.
<P>
<CENTER><a name="fig_18_10"><img src="f_18_10.gif" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/gifs/f_18_10.gif"></a><br>
<B>Figure 18.10</B> Example
of TCP's half-close.</CENTER>
<P>
Why is there a half-close? One example is the Unix
<TT>rsh</TT>(l) command, which executes a
command on another system. The command
<P>
<TT>sun % <B>rsh bsdi sort &lt;
datafile</B></TT>
<P>
executes the <TT>sort</TT> command
on the host <TT>bsdi</TT> with standard input
for the <TT>rsh</TT> command being read from
the file named <TT>datafile</TT>. A TCP connection
is created by rsh between itself and the program being executed
on the other host. The operation of <TT>rsh</TT>
is then simple: it copies standard input (<TT>datafile</TT>)
to the connection, and copies from the connection to standard
output (our terminal). Figure 18.11 shows the setup. (Remember
that a TCP connection is full-duplex.)

<P>
<CENTER><a name="fig_18_11"><img src="f_18_11.gif" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/gifs/f_18_11.gif"></a><br>
<B>Figure 18.11</B> The
command: <TT>rsh bsdi sort &lt; datafile</TT>.</CENTER>
<P>
On the remote host <TT>bsdi</TT>
the <TT>rshd</TT> server executes the <TT>sort</TT>
program so that its standard input and standard output are both
the TCP connection. Chapter 14 of [Stevens 1990] details the Unix
process structure involved, but what concerns us here is the use
of the TCP connection and the required use of TCP's half-close.
<P>
The <TT>sort</TT> program cannot
generate any output until all of its input has been read. All
the initial data across the connection is from the <TT>rsh</TT>
client to the <TT>sort</TT> server, sending
the file to be sorted. When the end-of-file is reached on the
input (<TT>datafile</TT>), the <TT>rsh</TT>
client performs a half-close on the TCP connection. The <TT>sort</TT>
server then receives an end-of-file on its standard input (the
TCP connection), sorts the file, and writes the result to its
standard output (the TCP connection). The <TT>rsh</TT>
client continues reading its end of the TCP connection, copying
the sorted file to its standard output.
<P>
Without a half-close, some other technique is needed
to let the client tell the server that the client is finished
sending data, but still let the client receive data from the server.
Two connections could be used as an alternative, but a single
connection with a half-close is better.
<a name="18_6"><H3>18.6 TCP State Transition Diagram</H3></a>
<P>
We've described numerous rules regarding the initiation
and termination of a TCP connection. These rules can be summarized
in a state transition diagram, which we show in <a href="#fig_18_12">Figure 18.12</a>.
<P>
The first thing to note in this diagram is that a
subset of the state transitions is &quot;typical.&quot; We've
marked the normal client transitions with a darker solid arrow,
and the normal server transitions with a darker dashed arrow.
<P>
Next, the two transitions leading to the ESTABLISHED
state correspond to opening a connection, and the two transitions
leading from the ESTABLISHED state are for the termination of
a connection. The ESTABLISHED state is where data transfer can
occur between the two ends in both directions. Later chapters
describe what happens in this state.
<P>
We've collected the four boxes in the lower left
of this diagram within a dashed box and labeled it &quot;active
close.&quot; Two other boxes (CLOSE_WAIT and LAST_ACK) are collected
in a dashed box with the label &quot;passive close.&quot;
<P>
The names of the 11 states (CLOSED, LISTEN, SYN_SENT,
etc.) in this figure were purposely chosen to be identical to
the states output by the <TT>netstat</TT>
command. The <TT>netstat</TT> names, in turn,
are almost identical to the names originally described in RFC
793. The state CLOSED is not really a state, but is the imaginary
starting point and ending point for the diagram.
<P>
The state transition from LISTEN to SYN_SENT is legal
but is not supported in Berkeley-derived implementations.
<P>
The transition from SYN_RCVD back to LISTEN is valid
only if the SYN_RCVD state was entered from the LISTEN state (the
normal scenario), not from the SYN_SENT state (a simultaneous
open). This means if we perform a passive open (enter LISTEN),
receive a SYN, send a SYN with an ACK (enter SYN_RCVD), and then
receive a reset instead of an ACK, the end point returns to the
LISTEN state and waits for another connection request to arrive.
<P>
<CENTER><a name="fig_18_12"><img src="f_18_12.gif" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/gifs/f_18_12.gif"></a><br>
<B>Figure 18.12</B> TCP
state transition diagram.</CENTER>
<P>
Figure 18.13 shows the normal TCP connection establishment
and termination, detailing the different states through which
the client and server pass. It is a redo of Figure 18.3 showing
only the states.
<P>
<CENTER><a name="fig_18_13"><img src="f_18_13.gif" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/gifs/f_18_13.gif"></a><br>
<B>Figure 18.13</B> TCP
states corresponding to normal connection establishment and termination.</CENTER>
<P>
We assume in Figure 18.13 that the client on the
left side does an active open, and the server on the right side
does a passive open. Although we show the client doing the active
close, as we mentioned earlier, either side can do the active
close.
<P>
You should follow through the state changes in Figure
18.13 using the state transition diagram in <a href="#fig_18_12">Figure 18.12</a>, making
certain you understand why each state change takes place.
<H4>2MSL Wait State</H4>
<P>
The TIME_WAIT state is also called the 2MSL wait
state. Every implementation must choose a value for the <I>maximum
segment lifetime</I> (MSL). It is the maximum amount of <I>time</I>
any segment can exist in the network before being discarded. We
know this time limit is bounded, since TCP segments are transmitted
as IP datagrams, and the IP datagram has the TTL field that limits
its lifetime.
<P>
<FONT SIZE=-1>RFC 793 [Postel 1981c] specifies the MSL as 2 minutes.
Common implementation values, however, are 30 seconds, 1 minute,
or 2 minutes.</FONT>
<P>
Recall from <a href="tracerou.htm#8_0" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/tracerou.htm#8_0">Chapter 8</a> that the real-world limit on
the lifetime of the IP datagram is based on the number of hops,
not a timer.
<P>
Given the MSL value for an implementation, the rule
is: when TCP performs an active close, and sends the final ACK,
that connection must stay in the TIME_WAIT state for twice the
MSL. This lets TCP resend the final ACK in case this ACK is lost
(in which case the other end will time out and retransmit its
final FIN).
<P>
Another effect of this 2MSL wait is that while the
TCP connection is in the 2MSL wait, the socket pair defining that
connection (client IP address, client port number, server IP address,
and server port number) cannot be reused. That connection can
only be reused when the 2MSL wait is over.
<P>
Unfortunately most implementations (i.e., the Berkeley-derived
ones) impose a more stringent constraint. By default a local port
number cannot be reused while that port number is the local port
number of a socket pair that is in the 2MSL wait. We'll see examples
of this common constraint below.
<P>
<FONT SIZE=-1>Some implementations and APIs provide a way to bypass
this restriction. With the sockets API, the <TT>SO_REUSEADDR</TT>
socket option can be specified. It lets the caller assign itself
a local port number that's in the 2MSL wait, but we'll see that
the rules of TCP still prevent this port number from being part
of a connection that is in the 2MSL wait.</FONT>
<P>
Any delayed segments that arrive for a connection
while it is in the 2MSL wait are discarded. Since the connection
defined by the socket pair in the 2MSL wait cannot be reused during
this time period, when we do establish a valid connection we know
that delayed segments from an earlier incarnation of this connection
cannot be misinterpreted as being part of the new connection.
(A connection is defined by a socket pair. New instances of a
connection are called <I>incarnations</I> of that connection.)
<P>
As we said with <a href="#fig_18_13">Figure 18.13</a>, it is normally the
client that does the active close and enters the TIME_WAIT state.
The server usually does the passive close, and does not go through
the TIME_WAIT state. The implication is that if we terminate a
client, and restart the same client immediately, that new client
cannot reuse the same local port number. This isn't a problem,
since clients normally use ephemeral ports, and don't care what
the local ephemeral port number is.
<P>
With servers, however, this changes, since servers
use well-known ports. If we terminate a server that has a connection
established, and immediately try to restart the server, the server
cannot assign its well-known port number to its end point, since
that port number is part of a connection that is in a 2MSL wait.
It may take from 1 to 4 minutes before the server can be restarted.
<P>
We can see this scenario using our sock program.
We start the server, connect to it from a client, and then terminate
the server:
<CENTER>
<TABLE>
<TR><TD COLSPAN=3 WIDTH=150><TT>sun % <B>sock -v -s 6666</B></TT>
</TD><TD COLSPAN=4 WIDTH=430><I>start as server, listening on port 6666</I>
</TD></TR>
<TR><TD COLSPAN=3 WIDTH=150></TD><TD COLSPAN=4 WIDTH=430><I>(execute client on</I> <TT>bsdi</TT> <I>that connects to this port)</I>
</TD></TR>
<TR><TD COLSPAN=7 WIDTH=590><TT>connection on 140.252.13.33.6666 from 140.252.13.35.1081</TT>
</TD></TR>
<TR><TD COLSPAN=3 WIDTH=150><TT><b>^?</b></TT></TD><TD COLSPAN=4 WIDTH=430><I>then type interrupt key to terminate server</I>
</TD></TR>
<TR><TD COLSPAN=3 WIDTH=150><TT>sun % <B>sock -s 6666</B></TT>
</TD><TD COLSPAN=4 WIDTH=430><I>and immediately try to restart server on same port</I>
</TD></TR>
<TR><TD COLSPAN=7 WIDTH=590><TT>can't bind local address: Address already in use</TT>
</TD></TR>
<TR><TD COLSPAN=3 WIDTH=150><TT>sun % <B>netstat</B></TT>
</TD><TD COLSPAN=4 WIDTH=430><I>let's check the state of the connection</I>
</TD></TR>
<TR><TD COLSPAN=3 WIDTH=150><TT>Active Internet connections</TT>
</TD><TD COLSPAN=4 WIDTH=430></TD></TR>
<TR><TD WIDTH=80><TT>Proto</TT></TD><TD WIDTH=80><TT>Recv-Q</TT>
</TD><TD WIDTH=80><TT>Send-Q</TT>
</TD><TD WIDTH=145><TT>Local Address</TT></TD><TD WIDTH=145><TT>Foreign Address</TT>
</TD><TD WIDTH=98><TT>(state)</TT></TD></TR>
<TR><TD WIDTH=80><TT>tcp</TT></TD><TD WIDTH=80><TT>0</TT></TD>
<TD WIDTH=80><tt>0</tt></TD><TD WIDTH=145><TT>sun.6666</TT>
</TD><TD WIDTH=145><TT>bsdi.1081</TT></TD><TD WIDTH=98><TT>TIME_WAIT</TT>
</TD></TR>
<TR><TD COLSPAN=3 WIDTH=150></TD><TD COLSPAN=4 WIDTH=400><I>many more lines that are deleted</I>
</TD></TR>
</TABLE>
</CENTER>
<P>
When we try to restart the server, the program outputs
an error message indicating it cannot bind its well-known port
number, because it's already in use (i.e., it's in a 2MSL wait).
<P>
We then immediately execute <TT>netstat</TT>
to see the state of the connection, and verify that it is indeed
in the TIME_WAIT state.
<P>
If we continually try to restart the server, and
measure the time until it succeeds, we can measure the 2MSL value.
On SunOS 4.1.3, SVR4, BSD/386, and AIX 3.2.2, it takes 1 minute
to restart the server, meaning the MSL is 30 seconds. Under Solaris
2.2 it takes 4 minutes to restart the server, implying an MSL
of 2 minutes.
<P>
We can see the same error from a client, if the client
tries to allocate a port that is part of a connection in the 2MSL
wait (something clients normally don't do):
<P><CENTER><TABLE>
<TR><TD WIDTH=295><TT>sun % <B>sock -v bsdi echo</B></TT>
</TD><TD WIDTH=395><I>start as client, connect to echo server</I>
</TD></TR>
<TR><TD COLSPAN=2 WIDTH=590><TT>connected on 140.252.13.33.1162 to 140.252.13.35.7</TT>
</TD></TR>
<TR><TD WIDTH=295><TT><B>hello there</B></TT>
</TD><TD WIDTH=395><I>type this line</I></TD>
</TR>
<TR><TD WIDTH=295><TT>hello there</TT></TD><TD WIDTH=395><I>and it's echoed by the server</I>
</TD></TR>
<TR><TD WIDTH=295><TT><B>^D</B></TT>
</TD><TD WIDTH=395><I>type end-of-file character to terminate client</I>
</TD></TR>
<TR><TD COLSPAN=2 WIDTH=590><TT>sun % <B>sock -b1162 bsdi echo</B></TT>
</TD></TR>
<TR><TD COLSPAN=2 WIDTH=590><TT>can't bind local address: Address already in use</TT>
</TD></TR>
</TABLE>
</CENTER><P>
The first time we execute the client we specify the
<TT>-v</TT> option to see what the local port
number is (1162). The second time we execute the client we specify
the <TT>-b</TT> option, telling the client
to assign itself 1162 as its local port number. As we expect,
the client can't do this, since that port number is part of a
connection that is in a 2MSL wait.
<P>
We need to reemphasize one effect of the 2MSL wait
because we'll encounter it in <a href="ftp_file.htm#27_0" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/ftp_file.htm#27_0">Chapter 27</a> with FTP, the File Transfer
Protocol. As we said earlier, it is a socket pair (that is, the
4-tuple consisting of a local IP address, local port, remote IP
address and remote port) that remains in the 2MSL wait. Although
many implementations allow a process to reuse a port number that
is part of a connection that is in the 2MSL wait (normally with
an option named <TT>SO_REUSEADDR</TT>), TCP
<I>cannot</I> allow a new connection to be created with the same
socket pair. We can see this with the following experiment:
<P>
<CENTER>
<TABLE>
<TR><TD WIDTH=320><TT>sun % <B>sock -v -s 6666</B></TT>
</TD><TD WIDTH=420><I>start as server, listening on port 6666<br>
(execute client on</I> <TT>bsdi</TT> <I>that connects to this port)</I>
</TD></TR>
<TR><TD COLSPAN=2 WIDTH=590><TT>connection on 140.252.13.33.6666 from 140.252.13.35.1098</TT>
</TD></TR>
<TR><TD WIDTH=320><TT><B>^?</B></TT>
</TD><TD WIDTH=420><I>then type interrupt key to terminate server</I>
</TD></TR>
<TR><TD WIDTH=320><TT>sun % <B>sock -b6666 bsdi 1098</B></TT>
</TD><TD WIDTH=420><I>try to start as client with local port 6666</I>
</TD></TR>
<TR><TD COLSPAN=2 WIDTH=590><TT>can't bind local address: Address already in use</TT>
</TD></TR>
<TR><TD WIDTH=320><TT>sun % <B>sock -A -b6666 bsdi 1098</B></TT>
</TD><TD WIDTH=420><I>try again, this time with -A option</I>
</TD></TR>
<TR><TD COLSPAN=2 WIDTH=590><TT>active open error: Address already in use</TT>
</TD></TR>
</TABLE>
</CENTER><P>
The first time we run our <TT>sock</TT>
program, we run it as a server on port 6666 and connect to it
from a client on the host <TT>bsdi</TT>. The
client's ephemeral port number is 1098. We terminate the server
so it does the active close. This causes the 4-tuple of 140.252.13.33
(local IP address), 6666 (local port number), 140.252.13.35 (foreign
IP address), and 1098 (foreign port number) to enter the 2MSL
wait on the server host.
<P>
The second time we run the program, we run it as
a client and try to specify the local port number as 6666 and
connect to host <TT>bsdi</TT> on port 1098.
But the program gets an error when it tries to assign itself the
local port number of 6666, because that port number is part of
the 4-tuple that is in the 2MSL wait state.
<P>
To try and get around this error we run the program
again, specifying the <TT>-A</TT> option,
which enables the <TT>SO_REUSEADDR</TT> option
that we mentioned. This lets the program assign itself the port
number 6666, but we then get an error when it tries to issue the
active open. Even though it can assign itself the port number
6666, it cannot create a connection to port 1098 on the host <TT>bsdi</TT>,
because the socket pair defining that connection is in the 2MSL
wait state.
<P>
What if we try to establish the connection from the
other host? First we must restart the server on <TT>sun</TT>
with the <TT>-A</TT> flag, since the local
port it needs (6666) is part of a connection that is in the 2MSL
wait:
<TABLE>
<TR><TD WIDTH=243><TT>sun % <B>sock -A -s 6666</B></TT>
</TD><TD WIDTH=347><I>start as server, listening on port 6666</I>
</TD></TR>
</TABLE>
<P>
Then, before the 2MSL wait is over on <TT>sun</TT>,
we start the client on <TT>bsdi</TT>:
<P>
<TT>bsdi % <B>sock -bl098 sun
6666<BR>
</B>connected on 140.252.13.35.1098 to 140.252.13.33.6666</TT>
<P>
Unfortunately it works! This is a violation of the
TCP specification, but is supported by most Berkeley-derived implementations.
These implementations allow a new connection request to arrive
for a connection that is in the TIME_WAIT state, if the new sequence
number is greater than the final sequence number from the previous
incarnation of this connection. In this case the ISN for the new
incarnation is set to the final sequence number from the previous
incarnation plus 128,000. The appendix of RFC 1185 [Jacobson,
Braden, and Zhang 1990] shows the pitfalls still possible with
this technique.
<P>
This implementation feature lets a client and server
continually reuse the same port number at each end for successive
incarnations of the same connection, but only if the server does
the active close. We'll see another example of this 2MSL wait
condition in <a href="ftp_file.htm#fig_27_8" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/ftp_file.htm#fig_27_8">Figure 27.8</a>, with FTP. See Exercise 18.5 also.
<H4>Quiet Time Concept</H4>
<P>
The 2MSL wait provides protection against delayed
segments from an earlier incarnation of a connection from being
interpreted as part of a new connection that uses the same local
and foreign IP addresses and port numbers. But this works only
if a host with connections in the 2MSL wait does not crash.
<P>
What if a host with ports in the 2MSL wait crashes,
reboots within MSL seconds, and immediately establishes new connections
using the same local and foreign IP addresses and port numbers
corresponding to the local ports that were in the 2MSL wait before
the crash? In this scenario, delayed segments from the connections
that existed before the crash can be misinterpreted as belonging
to the new connections created after the reboot. This can happen
regardless of how the initial sequence number is chosen after
the reboot.
<P>
To protect against this scenario, RFC 793 states
that TCP should not create any connections for MSL seconds after
rebooting. This is called the <I>quiet time.</I>
<P>
<FONT SIZE=-1>Few implementations abide by this since most hosts
take longer than MSL seconds to reboot after a crash.</FONT>
<H4>FIN WAIT 2 State</H4>
<P>
In the FIN_WAIT_2 state we have sent our FIN and
the other end has acknowledged it. Unless we have done a half-close,
we are waiting for the application on the other end to recognize
that it has received an end-of-file notification and close its
end of the connection, which sends us a FIN. Only when the process
at the other end does this close will our end move from the FIN_WAIT_2
to the TIME_WAIT state.
<P>
This means our end of the connection can remain in
this state forever. The other end is still in the CLOSE_WAIT state,
and can remain there forever, until the application decides to
issue its close.
<P>
<FONT SIZE=-1>Many Berkeley-derived implementations prevent this
infinite wait in the FIN_WAIT_2 state as follows. If the application
that does the active close does a complete close, not a half-close
indicating that it expects to receive data, then a timer is set.
If the connection is idle for 10 minutes plus 75 seconds, TCP
moves the connection into the CLOSED state. A comment in the code
acknowledges that this implementation feature violates the protocol
specification.</FONT>
<a name="18_7"><H3>18.7 Reset Segments</H3></a>
<P>
We've mentioned a bit in the TCP header named RST
for &quot;reset.&quot; In general, a reset is sent by TCP whenever
a segment arrives that doesn't appear correct for the referenced
connection. (We use the term &quot;referenced connection&quot;
to mean the connection specified by the destination IP address
and port number, and the source IP address and port number. This
is what RFC 793 calls a socket.)
<H4>Connection Request to Nonexistent Port</H4>
<P>
A common case for generating a reset is when a connection
request arrives and no process is listening on the destination
port. In the case of UDP, we saw in <a href="icmp_int.htm#6_5" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/icmp_int.htm#6_5">Section 6.5</a> that an ICMP port
unreachable was generated when a datagram arrived for a destination
port that was not in use. TCP uses a reset instead.
<P>
This example is trivial to generate-we use the Telnet
client and specify a port number that's not in use on the destination:
<TABLE>
<TR><TD WIDTH=320><TT>bsdi % telnet: svr4 20000</TT></TD><TD WIDTH=295><I>port 20000 should not be in use</I>
</TD></TR>
<TR><TD WIDTH=320><TT>Trying 140.252.13.34...</TT></TD><TD WIDTH=295>
</TD></TR>
<TR><TD COLSPAN=2 WIDTH=600><TT>telnet: Unable to connect to remote host: Connection refused</TT>
</TD></TR>
</TABLE>
<P>
This error message is output by the Telnet client
immediately. Figure 18.14 shows the packet exchange corresponding
to this command.
<P><CENTER>
<a name="fig_18_14"><TABLE></a>
<TR><TD WIDTH=26>1</TD><TD WIDTH=190><TT>0.0</TT>
</TD><TD WIDTH=520><TT>bsdi.1087 &gt; svr4.20000: S 297416193:297416193(0)
<BR>
win 4096 &lt;mss 1024&gt; [tos 0x10]</TT>
</TD></TR>
<TR><TD WIDTH=26>2</TD><TD WIDTH=190><TT>0.003771 (0.0038)</TT>
</TD><TD WIDTH=520><TT>svr4.20000 &gt; bsdi.1087: R 0:0(0)
<BR>
ack 297416194 win 0</TT>
</TD></TR>
</TABLE>
</CENTER>
<P>
<CENTER><B>Figure 18.14</B> Reset
generated by attempt to open connection to nonexistent port.</CENTER>
<P>
The values we need to examine in this figure are
the sequence number field and acknowledgment number field in the
reset. Because the ACK bit was not on in the arriving segment,
the sequence number of the reset is set to 0 and the acknowledgment
number is set to the incoming ISN plus the number of data bytes
in the segment. Although there is no real data in the arriving
segment, the SYN bit logically occupies 1 byte of sequence number
space; therefore, in this example the acknowledgment number in
the reset is set to the ISN, plus the data length (0), plus one
for the SYN bit.
<H4>Aborting a Connection</H4>
<P>
We saw in <a href="#18_2">Section 18.2</a> that the normal way to terminate
a connection is for one side to send a FIN. This is sometimes
called an <I>orderly release</I> since the FIN is sent after all
previously queued data has been sent, and there is normally no
loss of data. But it's also possible to abort a connection by
sending a reset instead of a FIN. This is sometimes called an
<I>abortive release.</I>
<P>
Aborting a connection provides two features to the
application: (1) any queued data is thrown away and the reset
is sent immediately, and (2) the receiver of the RST can tell
that the other end did an abort instead of a normal close. The
API being used by the application must provide a way to generate
the abort instead of a normal close.
<P>
We can watch this abort sequence happen using our
sock program. The sockets API provides this capability by using
the &quot;linger on close&quot; socket option (<TT>SO_LINGER</TT>).
We specify the <TT>-L</TT> option with a linger
time of 0. This causes the abort to be sent when the connection
is closed, instead of the normal FIN. We'll connect to a server
version of our sock program on <TT>svr4</TT>
and type one line of input:
<TABLE>
<TR><TD WIDTH=272><TT>bsdi % <B>sock -LO svr4 8888</B></TT>
</TD><TD WIDTH=390><I>this is the client; server shown later</I>
</TD></TR>
<TR><TD WIDTH=272><TT><B>hello, world</B></TT>
</TD><TD WIDTH=390><I>type one line of input that's sent to other end</I>
</TD></TR>
<TR><TD WIDTH=272><TT><B>^D</B></TT>
</TD><TD WIDTH=390><I>type end-of-file character to terminate client</I>
</TD></TR>
</TABLE>
<P>
Figure 18.15 shows the <TT>tcpdump</TT>
output for this example. (We have deleted all the window advertisements
in this figure, since they add nothing to the discussion.)
<CENTER>
<a name="fig_18_15"><TABLE></a>
<TR><TD WIDTH=26>1</TD><TD WIDTH=190><TT>0.0</TT>
</TD><TD WIDTH=520><TT>bsdi.1099 &gt; svr4.8888: S 671112193:671112193(0)
<BR>
&lt;mss 1024&gt;</TT>
</TD></TR>
<TR><TD WIDTH=26>2</TD><TD WIDTH=190><TT>0.004975 (0.0050)</TT>
</TD><TD WIDTH=520><TT>svr4.8888 &gt; bsdi.1099; S 3224959489:3224959489(0)
<BR>
ack 671112194 &lt;mss 1024&gt;</TT>
</TD></TR>
<TR><TD WIDTH=26>3</TD><TD WIDTH=190><TT>0.006656 (0.0017)</TT>
</TD><TD WIDTH=520><TT>bsdi.1099 &gt; svr4.8888: . ack 1</TT>
</TD></TR>
<TR><TD WIDTH=26>4</TD><TD WIDTH=190><TT>4.833073 (4.8264)</TT>
</TD><TD WIDTH=520><TT>bsdi.1099 &gt; svr4.8888: P 1:14(13) ack 1</TT>
</TD></TR>
<TR><TD WIDTH=26>5</TD><TD WIDTH=190><TT>5.026224 (0.1932)</TT>
</TD><TD WIDTH=520><TT>svr4.8888 &gt; bsdi.1099: . ack 14</TT>
</TD></TR>
<TR><TD WIDTH=26>6</TD><TD WIDTH=190><TT>9.527634 (4.5014)</TT>
</TD><TD WIDTH=520><TT>bsdi.1099 &gt; svr4.8888: R 14:14(0) ack 1</TT>
</TD></TR>
</TABLE>
</CENTER>
<P>
<CENTER><B>Figure 18.15</B> Aborting
a connection with a reset (RST) instead of a FIN.</CENTER>
<P>
Lines 1-3 show the normal connection establishment.
Line 4 sends the data line that we typed (12 characters plus the
Unix newline character), and line 5 is the acknowledgment of the
received data.
<P>
Line 6 corresponds to our typing the end-of-file
character (Control-D) to terminate the client. Since we specified
an abort instead of a normal close (the <TT>-L0</TT>
command-line option), the TCP on <TT>bsdi</TT>
sends an RST instead of the normal FIN. The RST segment contains
a sequence number and acknowledgment number. Also notice that
the RST segment elicits no response from the other end-it is not
acknowledged at all. The receiver of the reset aborts the connection
and advises the application that the connection was reset. We
get the following error on the server for this exchange:
<TABLE>
<TR><TD WIDTH=291><TT>svr4 % <B>sock -s 8888</B></TT>
</TD><TD WIDTH=300><I>run as server, listen on-port 8888</I>
</TD></TR>
<TR><TD WIDTH=291><TT><B>hello, world</B></TT>
</TD><TD WIDTH=300><I>this is what the client sent over</I>
</TD></TR>
<TR><TD COLSPAN=2 WIDTH=590><TT>read error: Connection reset by peer</TT>
</TD></TR>
</TABLE>
<P>
This server reads from the network and copies whatever
it receives to standard output. It normally ends by receiving
an end-of-file notification from its TCP, but here we see that
it receives an error when the RST arrives. The error is what we
expect: the connection was reset by the peer.
<H4>Detecting Half-Open Connections</H4>
<P>
A TCP connection is said to be <I>half-open</I> if
one end has closed or aborted the connection without the knowledge
of the other end. This can happen any time one of the two hosts
crashes. As long as there is no attempt to transfer data across
a half-open connection, the end that's still up won't detect that
the other end has crashed.
<P>
Another common cause of a half-open connection is
when a client host is powered off, instead of terminating the
client application and then shutting down the client host. This
happens when PCs are being used to run Telnet clients, for example,
and the users power off the PC at the end of the day. If there
was no data transfer going on when the PC was powered off, the
server will never la-row that the client disappeared. When the
user comes in the next morning, powers on the PC, and starts a
new Telnet client, a new occurrence of the server is started on
the server host. This can lead to many half-open TCP connections
on the server host. (In <a href="tcp_keep.htm#23_0" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/tcp_keep.htm#23_0">Chapter 23</a> we'll see a way for one end
of a TCP connection to discover that the other end has disappeared
using TCP's keepalive option.)
<P>
We can easily create a half-open connection. We'll
execute the Telnet client on <TT>bsdi</TT>,
connecting to the discard server on <TT>svr4</TT>.
We type one line of input, and watch it go across with <TT>tcpdump</TT>,
and then disconnect the Ethernet cable on the server's host, and
reboot the server host. This simulates the server host crashing.
(We disconnect the Ethernet cable before rebooting the server
to prevent it from sending a FIN out the open connections, which
some TCPs do when they are shut down.) After the server has rebooted,
we reconnect the cable, and try to send another line from the
client to the server. Since the server's TCP has rebooted, and
lost all memory of the connections that existed before it was
rebooted, it knows nothing about the connection that the data
segment references. The rule of TCP is that the receiver responds
with a reset.
<TABLE>
<TR><TD WIDTH=350><TT>bsdi % <B>telnet svr4 discard</B></TT>
</TD><TD WIDTH=335><I>start the client</I>
</TD></TR>
<TR><TD WIDTH=350><TT>Trying 140.252.13.34...</TT></TD><TD WIDTH=335>
</TD></TR>
<TR><TD WIDTH=350><TT>Connected to svr4.</TT></TD><TD WIDTH=335>
</TD></TR>
<TR><TD WIDTH=350><TT>Escape character is '^]'</TT></TD><TD WIDTH=335>
</TD></TR>
<TR><TD WIDTH=350><TT><B>hi there</B></TT>
</TD><TD WIDTH=335><I>this line is sent OK.</I>
</TD></TR>
<TR><TD WIDTH=350></TD><TD WIDTH=335><I>here is where we reboot the server host</I>
</TD></TR>
<TR><TD WIDTH=350><TT>another line</TT></TD><TD WIDTH=335><I>and this one elicits a reset</I>
</TD></TR>
<TR><TD WIDTH=350><TT>Connection closed by foreign host.</TT>
</TD><TD WIDTH=335></TD></TR>
</TABLE>
<P>

Figure 18.16 shows the <TT>tcpdump</TT>
output for this example. (We have removed from this output the
window advertisements, the type-of-service information, and the
MSS announcements, since they add nothing to the discussion.)
<P>
<CENTER>
<a name="fig_18_16"><TABLE></a>
<TR><TD WIDTH=15>1</TD><TD WIDTH=220><TT>0.0</TT>
</TD><TD WIDTH=520><TT>bsdi.1102 &gt; svr4.discard: S1591752193:1591752193(0)</TT>
</TD></TR>
<TR><TD WIDTH=15>2</TD><TD WIDTH=220><TT>0.004811 (0.0048)</TT>
</TD><TD WIDTH=520><TT>svr4.discard &gt; bsdi.1102: S26368001:26368001(0)
<BR>
ack 1591752194</TT>
</TD></TR>
<TR><TD WIDTH=15>3</TD><TD WIDTH=220><TT>0.006516 (0.0017)</TT>
</TD><TD WIDTH=520><TT>bsdi.1102 &gt; svr4.discard: . ack 1</TT>
</TD></TR>
<TR><TD WIDTH=15>4</TD><TD WIDTH=220><TT>5.167679 (5.1612)</TT>
</TD><TD WIDTH=520><TT>bsdi.1102 &gt; svr4.discard: P 1:11(10) ack 1</TT>
</TD></TR>
<TR><TD WIDTH=15>5</TD><TD WIDTH=220><TT>5.201662 (0.0340)</TT>
</TD><TD WIDTH=520><TT>svr4.discard &gt; bsdi.1102: . ack 11</TT>
</TD></TR>
<TR><TD WIDTH=15>6</TD><TD WIDTH=220><TT>194.909929 (189.7083)</TT>
</TD><TD WIDTH=520><TT>bsdi.1102 &gt; svr4.discard: P 11:25(14) ack 1</TT>
</TD></TR>
<TR><TD WIDTH=15>7</TD><TD WIDTH=220><TT>194.914957 (0.0050)</TT>
</TD><TD WIDTH=520><TT>arp who-has bsdi tell svr4</TT></TD></TR>
<TR><TD WIDTH=15>8</TD><TD WIDTH=220><TT>194.915678 (0.0007)</TT>
</TD><TD WIDTH=520><TT>arp reply bsdi is-at 0:0:c0:6f:2d:40</TT>
</TD></TR>
<TR><TD WIDTH=15>9</TD><TD WIDTH=220><TT>194.918225 (0.0025)</TT>
</TD><TD WIDTH=520><TT>svr4.discard &gt; bsdi.1102: R26368002:26368002 (0)</TT>
</TD></TR>
</TABLE>
</CENTER>
<P>
<CENTER><B>Figure 18.16</B> Reset
in response to data segment on a half-open connection.</CENTER>
<P>

Lines 1-3 are the normal connection establishment.
Line 4 sends the line &quot;hi there&quot; to the discard server,
and line 5 is the acknowledgment.
<P>
At this point we disconnect the Ethernet cable from
<TT>svr4</TT>, reboot it, and reconnect the
cable. This takes almost 190 seconds. We then type the next line
of input to the client (&quot;another line&quot;) and when we
type the return key the line is sent to the server (line 6 in
Figure 18.16). This elicits a response from the server, but note
that since the server was rebooted, its ARP cache is empty, so
an ARP request and reply are required (lines 7 and 8). Then the
reset is sent in line 9. The client receives the reset and outputs
that the connection was terminated <I>by</I> the foreign host.
(The final message output by the Telnet client is not as informative
as it could be.)
<a name="18_8"><H3>18.8 Simultaneous Open</H3></a>
<P>
It is possible, although improbable, for two applications
to both perform an active open to each other at the same time.
Each end must transmit a SYN, and the SYNs must pass each other
on the network. It also requires each end to have a local port
number that is well known to the other end. This is called a <I>simultaneous
open.</I>
<P>
For example, one application on host A could have
a local port of 7777 and perform an active open to port 8888 on
host B. The application on host B would have a local port of 8888
and perform an active open to port 7777 on host A.
<P>
This is <I>not</I> the same as connecting a Telnet
client on host A to the Telnet server on host B, at the same time
that a Telnet client on host B is connecting to the Telnet server
on host A. In this Telnet scenario, both Telnet servers perform
passive opens, not active opens, and the Telnet clients assign
themselves an ephemeral port number, not a port number that is
well known to the other Telnet server.
<P>
TCP was purposely designed to handle simultaneous
opens and the rule is that only one connection results from this,
not two connections. (Other protocol suites, notably the OSI transport
layer, create two connections in this scenario, not one.)
<P>
When a simultaneous open occurs the state transitions
differ from those shown in <a href="#fig_18_13">Figure 18.13</a>. Both ends send a SYN
at about the same time, entering the SYN_SENT state. When each
end receives the SYN, the state changes to SYN_RCVD (<a href="#fig_18_12">Figure 18.12</a>),
and each end resends the SYN and acknowledges the received SYN.
When each end receives the SYN plus the ACK, the state changes
to ESTABLISHED. These state changes are summarized in Figure 18.17.

<P>
<CENTER><a name="fig_18_17"><img src="f_18_17.gif" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/gifs/f_18_17.gif"></a><br>
<B>Figure 18.17</B> Segments
exchanged during simultaneous open.</CENTER>
<P>
A simultaneous open requires the exchange of four
segments, one more than the normal three-way handshake. Also notice
that we don't call either end a client or a server, because both
ends act as client and server.
<H4>An Example</H4>
<P>
It is possible, though hard, to generate a simultaneous
open. The two ends must be started at about the same time, so
that the SYNs cross each other. Having a long round-trip time
between the two ends helps, to let the SYNs cross. To do this
we'll execute one end on our host <TT>bsdi</TT>,
and the other end on the host <TT>vangogh.cs.berkeley.edu</TT>.
Since there is a dialup SLIP link between them, the round-trip
time should be long enough (a few hundred milliseconds) to let
the SYNs cross.
<P>
One end (<TT>bsdi</TT>) assigns
itself a local port of 8888 (the -b command-line option) and performs
an active open to port 7777 on the other host:
<TABLE>
<TR><TD COLSPAN=2 WIDTH=590><TT>bsdi % sock -v -b8888 vangogh.cs.berkeley.edu 7777</TT>
</TD></TR>
<TR><TD COLSPAN=2 WIDTH=590><TT>connected on 140.252.13.35.8888 to 128.32.130.2.7777</TT>
</TD></TR>
<TR><TD COLSPAN=2 WIDTH=590><TT>TCP_MAXSEG = 512</TT></TD></TR>
<TR><TD WIDTH=295><TT>hello, world</TT></TD><TD WIDTH=295><I>we type this line</I>
</TD></TR>
<TR><TD WIDTH=295><TT>and hi there</TT></TD><TD WIDTH=295><I>this line was typed on other end</I>
</TD></TR>
<TR><TD WIDTH=295><TT>connection closed by peer</TT></TD><TD WIDTH=295><I>this is output when FIN received</I>
</TD></TR>
</TABLE>
<P>
The other end is started at about the same time,
assigns itself a local port of 7777, and performs an active open
to port 8888:
<TABLE>
<TR><TD COLSPAN=2 WIDTH=590><TT>vangogh % <B>sock -v -b7777 bsdi.tuc.noao.edu 8888</B></TT>
</TD></TR>
<TR><TD COLSPAN=2 WIDTH=590><TT>connected on 128.32.130.2.7777 to 140.252.13.35.8888</TT>
</TD></TR>
<TR><TD COLSPAN=2 WIDTH=590><TT>TCP_MAXSEG = 512</TT></TD></TR>
<TR><TD WIDTH=295><TT>hello, world</TT></TD><TD WIDTH=295><I>this is typed on the other end</I>
</TD></TR>
<TR><TD WIDTH=295><TT><B>and hi there</B></TT>
</TD><TD WIDTH=295><I>we type this line</I>
</TD></TR>
<TR><TD WIDTH=295><TT><B>^D</B></TT>
</TD><TD WIDTH=295><I>and then type our EOF character</I>
</TD></TR>
</TABLE>
<P>
We specify the <TT>-v</TT> flag
to our <TT>sock</TT> program to verify the
IP address and port numbers on each end of the connection. This
flag also prints the MSS used by each end of the connection. We
also type in one line on each end, which is sent to the other
end and printed, to verify that both ends are indeed talking to
each other.
<P>
Figure 18.18 shows the exchange of segments across
the connection. (We have deleted some new TCP options that appear
in the original SYN from <TT>vangogh</TT>,
a 4.4BSD system. We describe these newer options in <a href="#18_10">Section 18.10</a>.)
Notice the two SYNs (lines 1 and 2) followed by the two SYNs with
ACKs (lines 3 and 4). These perform the simultaneous open.
<P>
Line 5 shows the input line &quot;hello, world&quot;
going from <TT>bsdi</TT> to <TT>vangogh</TT>,
with the acknowledgment in line 6. Lines 7 and 8 correspond to
the line &quot;and hi there&quot; going in the other direction.
Lines 9-12 show the normal connection termination.
<P>
<FONT SIZE=-1>Many Berkeley-derived implementations do not support
the simultaneous open correctly. On these systems, if you can
get the SYNs to cross, you end up with an infinite exchange of
segments, each with a SYN and an ACK, in each direction. The transition
from the SYN_SENT state to the SYN_RCVD state in <a href="#fig_18_12">Figure 18.12</a>
is not always tested in many implementations.</FONT>
<P>
<CENTER><a name="fig_18_18"><TABLE></a>
<TR><TD WIDTH=25>1</TD><TD WIDTH=189><TT>0.0</TT>
</TD><TD WIDTH=530><TT>bsdi.8888 &gt;vangogh.7777: S 91904001:91904001(0)
<BR>
win 4096 &lt;mss 512&gt;</TT>
</TD></TR>
<TR><TD WIDTH=25>2</TD><TD WIDTH=189><TT>0.213782 (0.2138)</TT>
</TD><TD WIDTH=530><TT>vangogh.7777 &gt; bsdi.8888: S 1058199041:1058199041(0)
<BR>
win 8192 &lt;mss 512&gt;</TT>
</TD></TR>
<TR><TD WIDTH=25>3</TD><TD WIDTH=189><TT>0.215399 (0.0016)</TT>
</TD><TD WIDTH=530><TT>bsdi.8888 &gt; vangogh.7777: S 91904001:91904001(0)
<BR>
ack 1058199042 win 4096 &lt;mss 512&gt;</TT>
</TD></TR>
<TR><TD WIDTH=25>4</TD><TD WIDTH=189><TT>0.340405 (0.1250)</TT>
</TD><TD WIDTH=530><TT>vangogh.7777 &gt; bsdi.8888: S 1058199041:1058199041(0)
<BR>
ack 91904002 win 8192 &lt;mss 512&gt;</TT>
</TD></TR>
<TR><TD WIDTH=25>5</TD><TD WIDTH=189><TT>5.633142 (5.2927)</TT>
</TD><TD WIDTH=530><TT>bsdi.8888 &gt; vangogh.7777: P 1:14(13) ack 1 win 4096</TT>
</TD></TR>
<TR><TD WIDTH=25>6</TD><TD WIDTH=189><TT>6.100366 (0.4672)</TT>
</TD><TD WIDTH=530><TT>vangogh.7777 &gt; bsdi.8888: . ack 14 win 8192</TT>
</TD></TR>
<TR><TD WIDTH=25>7</TD><TD WIDTH=189><TT>9.640214 (3.5398)</TT>
</TD><TD WIDTH=530><TT>vangogh.7777 &gt; bsdi.8888: P 1:14(13) ack 14 win 8192</TT>
</TD></TR>
<TR><TD WIDTH=25>8</TD><TD WIDTH=189><TT>9.796417 (0.1562)</TT>
</TD><TD WIDTH=530><TT>bsdi.8888 &gt; vangogh.7777: . ack 14 win 4096</TT>
</TD></TR>
<TR><TD WIDTH=25>9</TD><TD WIDTH=189><TT>13.060395 (3.2640)</TT>
</TD><TD WIDTH=530><TT>vangogh.7777 &gt; bsdi.8888: F 14:14(0) ack 14 win 8192</TT>
</TD></TR>
<TR><TD WIDTH=25>10</TD><TD WIDTH=189><TT>13.061828 (0.0014)</TT>
</TD><TD WIDTH=530><TT>bsdi.8888 &gt; vangogh.7777: . ack 15 win 4096</TT>
</TD></TR>
<TR><TD WIDTH=25>11</TD><TD WIDTH=189><TT>13.079769 (0.0179)</TT>
</TD><TD WIDTH=530><TT>bsdi.8888 &gt; vangogh.7777: F 14:14(0) ack 15 win 4096</TT>
</TD></TR>
<TR><TD WIDTH=25>12</TD><TD WIDTH=189><TT>13.299940 (0.2202)</TT>
</TD><TD WIDTH=530><TT>vangogh.7777 &gt; bsdi.8888: . ack 15 win 8192</TT>
</TD></TR>
</TABLE>
</CENTER><P>
<CENTER><B>Figure 18.18</B> Exchange
of segments during simultaneous open.</CENTER>
<a name="18_9"><H3>18.9 Simultaneous Close</H3></a>
<P>
We said earlier that one side (often, but not always,
the client) performs the active close, causing the first FIN to
be sent. It's also possible for both sides to perform an active
close, and the TCP protocol allows for this <I>simultaneous close.</I>
<P>
In terms of <a href="#fig_18_12">Figure 18.12</a>, both ends go from ESTABLISHED
to FIN_WAIT_1 when the application issues the close. This causes
both FINs to be sent, and they probably pass each other somewhere
in the network. When the FIN is received, each end transitions
from FIN_WAIT_1 to the CLOSING state, and each state sends its
final ACK. When each end receives the final ACK, the state changes
to TIME_WAIT. Figure 18.19 summarizes these state changes.

<P>
<CENTER><a name="fig_18_19"><img src="f_18_19.gif" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/gifs/f_18_19.gif"></a><br>
<B>Figure 18.19</B> Segments
exchanged during simultaneous close.</CENTER>
<P>
With a simultaneous close the same number of segments
are exchanged as in the normal close.
<a name="18_10"><H3>18.10 TCP Options</H3></a>
<P>
The TCP header can contain options (<a href="tcp_tran.htm#fig_17_2" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/tcp_tran.htm#fig_17_2">Figure 17.2</a>).
The only options defined in the original TCP specification are
the end of option list, no operation, and the maximum segment
size option. We have seen the MSS option in almost every SYN segment
in our examples.
<P>
Newer RFCs, specifically RFC 1323 [Jacobson, Braden,
and Borman 1992], define additional TCP options, most of which
are found only in the latest implementations. (We describe these
new options in <a href="tcp_fut.htm#24_0" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/tcp_fut.htm#24_0">Chapter 24</a>.) Figure 18.20 shows the format of the
current TCP options-those from RFC 793 and RFC 1323.
<P>
<CENTER><a name="fig_18_20"><img src="f_18_20.gif" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/gifs/f_18_20.gif"></a><br>
<B>Figure 18.20</B> TCP
options.</CENTER>
<P>
Every option begins with a 1-byte <I>kind</I> that
specifies the type of option. The options with a <I>kind</I> of
0 and 1 occupy a single byte. The other options have a <I>len</I>
byte that follows the <I>kind</I> byte. The length is the total
length, including the <I>kind</I> and <I>len</I> bytes.
<P>
The reason for the no operation (NOP) option is to
allow the sender to pad fields to a multiple of 4 bytes. If we
initiate a TCP connection from a 4.4BSD system, the following
TCP options are output by <TT>tcpdump</TT>
on the initial SYN segment:
<P>
<TT>&lt;mss 512,nop,wscale 0,nop,nop,timestamp 146647 0&gt;</TT>
<P>
The MSS option is set to 512, followed by a NOP,
followed by the window scale option. The reason for the first
NOP is to pad the 3-byte window scale option to a 4-byte boundary.
Similarly, the IO-byte timestamp option is preceded by two NOPs,
to occupy 12 bytes, placing the two 4-byte timestamps onto 4-byte
boundaries.
<P>
<FONT SIZE=-1>Four other options have been proposed, with <I>kinds
of</I> 4, 5, 6, and 7 called the selective-ACK and echo options.
We don't show them in Figure 18.20 because the echo options have
been replaced with the timestamp option, and selective ACKs, as
currently defined, are still under discussion and were not included
in RFC 1323. Also, the T/TCP proposal for TCP transactions (<a href="tcp_fut.htm#24_7" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/tcp_fut.htm#24_7">Section 24.7</a>)
specifies three options with <I>kinds</I> of 11, 12, and
13.</FONT>
<a name="18_11"><H3>18.11 TCP Server Design</H3></a>
<P>
We said in <a href="introduc.htm#1_8" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/introduc.htm#1_8">Section 1.8</a> that most TCP servers are
concurrent. When a new connection request arrives at a server,
the server accepts the connection and invokes a new process to
handle the new client. Depending on the operating system, various
techniques are used to invoke the new server. Under Unix the common
technique is to create a new process using the <TT>fork</TT>
function. Lightweight processes (threads) can also be used, if
supported.
<P>
What we're interested in is the interaction of TCP
with concurrent servers. We need to answer the following questions:
how are the port numbers handled when a server accepts a new connection
request from a client, and what happens if multiple connection
requests arrive at about the same time?
<H4>TCP Server Port Numbers</H4>
<P>
We can see how TCP handles the port numbers by watching
any TCP server. We'll watch the Telnet server using the <TT>netstat</TT>
command. The following output is on a system with no active Telnet
connections. (We have deleted all the lines except the one showing
the Telnet server.)
<TABLE>
<TR><TD COLSPAN=6 WIDTH=555><TT>sun % <B>netstat -a -n -f inet</B></TT>
</TD></TR>
<TR><TD COLSPAN=6 WIDTH=555><TT>Active Internet connections (including servers)</TT>
</TD></TR>
<TR><TD WIDTH=64><TT>Proto</TT></TD><TD WIDTH=76><TT>Recv-Q</TT>
</TD><TD WIDTH=85><TT>Send-Q</TT></TD><TD WIDTH=160><TT>Local Address</TT>
</TD><TD WIDTH=160><TT>Foreign Address</TT></TD><TD WIDTH=95><TT>(state)</TT>
</TD></TR>
<TR><TD WIDTH=64><TT>tcp</TT></TD><TD WIDTH=76><TT>0</TT></TD>
<TD WIDTH=85><TT>0</TT></TD><TD WIDTH=160><TT>*.23</TT></TD><TD WIDTH=160><TT>*.*</TT>
</TD><TD WIDTH=95><TT>LISTEN</TT></TD></TR>
</TABLE>
<P>
The <TT>-a</TT> flag reports
on all network end points, not just those that are ESTABLISHED.
The <TT>-n</TT> flag prints IP addresses as
dotted-decimal numbers, instead of trying to use the DNS to convert
the address to a name, and prints numeric port numbers (e.g.,
23) instead of service names (e.g., Telnet). The <TT>-f
inet</TT> option reports only TCP and UDP end points.
<P>
The local address is output as <tt>*.23</tt>, where the asterisk
is normally called the <I>wildcard</I> character. This means that
an incoming connection request (i.e., a SYN) will be accepted
on any local interface. If the host were multihomed, we could
specify a single IP address for the local IP address (one of the
host's IP addresses), and only connections received on that interface
would be accepted. (We'll see an example of this later in this
section.) The local port is 23, the well-known port number for
Telnet.
<P>
The foreign address is output as <tt>*.*</tt>, which means
the foreign IP address and foreign port number are not known yet,
because the end point is in the LISTEN state, waiting for a connection
to arrive.
<P>
We now start a Telnet client on the host <TT>slip</TT>
(140.252.13.65) that connects to this server. Here are the relevant
lines from the <TT>netstat</TT> output:
<TABLE>
<TR><TD WIDTH=64><TT>Proto</TT></TD><TD WIDTH=66><TT>Recv-Q</TT>
</TD><TD WIDTH=66><tt>Send-Q</tt>
</TD><TD WIDTH=151><TT>Local Address</TT></TD><TD WIDTH=161><TT>Foreign Address</TT>
</TD><TD WIDTH=104><TT>(state)</TT></TD></TR>
<TR><TD WIDTH=64><TT>tcp</TT></TD><TD WIDTH=66><TT>0</TT></TD>
<TD WIDTH=66><tt>0</tt></TD><TD WIDTH=151><TT>140.252.13.33.23</TT>
</TD><TD WIDTH=161><TT>140.252.13.65.1029</TT></TD><TD WIDTH=104><TT>ESTABLISHED</TT>
</TD></TR>
<TR><TD WIDTH=64><TT>tcp</TT></TD><TD WIDTH=66><TT>0</TT></TD>
<TD WIDTH=66><tt>0</tt></TD><TD WIDTH=151><TT>*.23</TT>
</TD><TD WIDTH=161><TT>*.*</TT></TD><TD WIDTH=104><TT>LISTEN</TT>
</TD></TR>
</TABLE>
<P>
The first line for port 23 is the ESTABLISHED connection.
All four elements of the local and foreign address are filled
in for this connection: the local IP address and port number,
and the foreign IP address and port number. The local IP address
corresponds to the interface on which the connection request arrived
(the Ethernet interface, 140.252.13.33).
<P>
The end point in the LISTEN state is left alone.
This is the end point that the concurrent server uses to accept
future connection requests. It is the TCP module in the kernel
that creates the new end point in the ESTABLISHED state, when
the incoming connection request arrives and is accepted. Also
notice that the port number for the ESTABLISHED connection doesn't
change: it's 23, the same as the LISTEN end point.
<P>
We now initiate another Telnet client from the same
client (<TT>slip</TT>) to this server. Here
is the relevant <TT>netstat</TT> output:
<TABLE>
<TR><TD WIDTH=64><TT>Proto</TT></TD><TD WIDTH=66><TT>Recv-Q</TT>
</TD><TD WIDTH=66><tt>Send-Q</tt>
</TD><TD WIDTH=151><TT>Local Address</TT></TD><TD WIDTH=161><TT>Foreign Address</TT>
</TD><TD WIDTH=113><TT>(state)</TT></TD></TR>
<TR><TD WIDTH=64><TT>tcp</TT></TD><TD WIDTH=66><TT>0</TT></TD>
<TD WIDTH=66><tt>0</tt></TD><TD WIDTH=151><TT>140.252.13.33.23</TT>
</TD><TD WIDTH=161><TT>140.252.13.65.1030</TT></TD><TD WIDTH=113><TT>ESTABLISHED</TT>
</TD></TR>
<TR><TD WIDTH=64><TT>tcp</TT></TD><TD WIDTH=66><TT>0</TT></TD>
<TD WIDTH=66><tt>0</tt></TD><TD WIDTH=151><TT>140.252.13.33.23</TT>
</TD><TD WIDTH=161><TT>140.252.13.65.1029</TT></TD><TD WIDTH=113><TT>ESTABLISHED</TT>
</TD></TR>
<TR><TD WIDTH=64><TT>tcp</TT></TD><TD WIDTH=66><TT>0</TT></TD>
<TD WIDTH=66><tt>0</tt></TD><TD WIDTH=151><TT>*.23</TT>
</TD><TD WIDTH=161><TT>*.*</TT></TD><TD WIDTH=113><TT>LISTEN</TT>
</TD></TR>
</TABLE>
<P>
We now have two ESTABLISHED connections from the
same host to the same server. Both have a local port number of
23. This is not a problem for TCP since the foreign port numbers
are different. They must be different because each of the Telnet
clients uses an ephemeral port, and the definition of an ephemeral
port is one that is not currently in use on that host (<TT>slip</TT>).
<P>
This example reiterates that TCP demultiplexes incoming
segments using all four values that comprise the local and foreign
addresses: destination IP address, destination port number, source
IP address, and source port number. TCP cannot determine which
process gets an incoming segment by looking at the destination
port number only. Also, the only one of the three end points at
port 23 that will receive incoming connection requests is the
one in the LISTEN state. The end points in the ESTABLISHED state
cannot receive SYN segments, and the end point in the LISTEN state
cannot receive data segments.
<P>
Next we initiate a third Telnet client, from the
host <TT>solaris</TT> that is across the SLIP
link from <TT>sun</TT>, and not on its Ethernet.
<TABLE>
<TR><TD WIDTH=64><TT>Proto</TT></TD><TD WIDTH=66><TT>Recv-Q</TT>
</TD><TD WIDTH=66><tt>Send-Q</tt>
</TD><TD WIDTH=151><TT>Local Address</TT></TD><TD WIDTH=161><TT>Foreign Address</TT>
</TD><TD WIDTH=104><TT>(state)</TT></TD></TR>
<TR><TD WIDTH=64><TT>tcp</TT></TD><TD WIDTH=66><TT>0</TT></TD>
<TD WIDTH=66><tt>0</tt></TD><TD WIDTH=151><TT>140.252.1.29.23</TT>
</TD><TD WIDTH=161><TT>140.252.1.32.34603</TT></TD><TD WIDTH=104><TT>ESTABLISHED</TT>
</TD></TR>
<TR><TD WIDTH=64><TT>tcp</TT></TD><TD WIDTH=66><TT>0</TT></TD>
<TD WIDTH=66><tt>0</tt></TD><TD WIDTH=151><TT>140.252.13.33.23</TT>
</TD><TD WIDTH=161><TT>140.252.13.65.1030</TT></TD><TD WIDTH=104><TT>ESTABLISHED</TT>
</TD></TR>
<TR><TD WIDTH=64><TT>tcp</TT></TD><TD WIDTH=66><TT>0</TT></TD>
<TD WIDTH=66><tt>0</tt></TD><TD WIDTH=151><TT>140.252.13.33.23</TT>
</TD><TD WIDTH=161><TT>140.252.13.65.1029</TT></TD><TD WIDTH=104><TT>ESTABLISHED</TT>
</TD></TR>
<TR><TD WIDTH=64><TT>tcp</TT></TD><TD WIDTH=66><TT>0</TT></TD>
<TD WIDTH=66><tt>0</tt></TD><TD WIDTH=151><TT>*.23</TT>
</TD><TD WIDTH=161><TT>*.*</TT></TD><TD WIDTH=104><TT>LISTEN</TT>
</TD></TR>
</TABLE>
<P>
The local IP address of the first ESTABLISHED connection
now corresponds to the interface address of SLIP link on the multihomed
host <TT>sun</TT> (140.252.1.29).
<H4>Restricting Local IP Address</H4>
<P>
We can see what happens when the server does not
wildcard its local IP address, setting it to one particular local
interface address instead. If we specify an IP address (or host-name)
to our sock program when we invoke it as a server, that IP address
becomes the local IP address of the listening end point. For example
<P>
<TT>sun % <B>sock -s 140.252.1.29
8888</B></TT>
<P>
restricts this server to connections arriving on
the SLIP interface (140.252.1.29). The <TT>netstat</TT>
output reflects this:
<TABLE>
<TR><TD WIDTH=64><TT>Proto</TT></TD><TD WIDTH=66><TT>Recv-Q</TT>
</TD><TD WIDTH=66><tt>Send-Q</tt>
</TD><TD WIDTH=200><TT>Local Address</TT></TD><TD WIDTH=200><TT>Foreign Address</TT>
</TD><TD WIDTH=82><TT>(state)</TT></TD></TR>
<TR><TD WIDTH=64><TT>tcp</TT></TD><TD WIDTH=66><TT>0</TT></TD>
<TD WIDTH=66><tt>0</tt></TD><TD WIDTH=200><TT>140.252.1.29.8888</TT>
</TD><TD WIDTH=200><TT>*.*</TT></TD><TD WIDTH=82><TT>LISTEN</TT>
</TD></TR>
</TABLE>
<P>
If we connect to this server across the SLIP link,
from the host <TT>solaris</TT>, it works.
<TABLE>
<TR><TD WIDTH=64><TT>Proto</TT></TD><TD WIDTH=66><TT>Recv-Q</TT>
</TD><TD WIDTH=66><tt>Send-Q</tt>
</TD><TD WIDTH=200><TT>Local Address</TT></TD><TD WIDTH=200><TT>Foreign Address</TT>
</TD><TD WIDTH=113><TT>(state)</TT></TD></TR>
<TR><TD WIDTH=64><TT>tcp</TT></TD><TD WIDTH=66><TT>0</TT></TD>
<TD WIDTH=66><tt>0</tt></TD><TD WIDTH=200><TT>140.252.1.29.8888</TT>
</TD><TD WIDTH=200><TT>140.252.1.32.34614</TT></TD><TD WIDTH=113><TT>ESTABLISHED</TT>
</TD></TR>
<TR><TD WIDTH=64><TT>tcp</TT></TD><TD WIDTH=66><TT>0</TT></TD>
<TD WIDTH=66><tt>0</tt></TD><TD WIDTH=200><TT>140.252.1.29.8888</TT>
</TD><TD WIDTH=200><TT>*.*</TT></TD><TD WIDTH=113><TT>LISTEN</TT>
</TD></TR>
</TABLE>
<P>
But if we try to connect to this server from a host
on the Ethernet (140.252.13), the connection request is not accepted
by the TCP module. If we watch it with <TT>tcpdump</TT>
the SYN is responded to with an RST, as we show in Figure 18.21.
<CENTER>
<a name="fig_18_21"><TABLE></a>
<TR><TD WIDTH=17>1</TD><TD WIDTH=180><TT>0.0</TT>
</TD><TD WIDTH=525><TT>bsdi.l026 &gt; sun.8888: S 3657920001:3657920001(0)
<BR>
win 4096 &lt;mss 1024&gt;</TT>
</TD></TR>
<TR><TD WIDTH=17>2</TD><TD WIDTH=180><TT>0.000859 (0.0009)</TT>
</TD><TD WIDTH=525><TT>sun.8888 &gt; bsdi.l026: R 0:0(0) ack 3657920002 win 0</TT>
</TD></TR>
</TABLE>
</CENTER>
<P>
<CENTER><B>Figure 18.21</B> Rejection
of a connection request based on local IP address of server.</CENTER>
<P>
The server application never sees the connection
request - the rejection is done by the kernel's TCP module, based
on the local IP address specified by the application.
<H4>Restricting Foreign IP Address</H4>
<P>
In <a href="udp_user.htm#11_12" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/udp_user.htm#11_12">Section 11.12</a> we saw that a UDP server can normally
specify the foreign IP address and foreign port, in addition to
specifying the local IP address and local port. The interface
functions shown in RFC 793 allow a server doing a passive open
to have either a fully specified foreign socket (to wait for a
particular client to issue an active open) or a unspecified foreign
socket (to wait for any client).
<P>
Unfortunately, most APIs don't provide a way to do
this. The server must leave the foreign socket unspecified, wait
for the connection to arrive, and then examine the IP address
and port number of the client.
<P>
Figure 18.22 summarizes the three types of address
bindings that a TCP server can establish for itself. In all cases,
<I>lport</I> is the server's well-known port and <I>localIP</I>
must be the IP address of a local interface. The ordering of the
three rows in the table is the order that the TCP module applies
when trying to determine which local end point receives an incoming
connection request. The most specific binding (the first row,
if supported) is tried first, and the least specific (the last
row with both IP addresses wild-carded) is tried last.
<P>
<CENTER>
<a name="fig_18_22"><TABLE BORDER=1></a>
<TR><TD WIDTH=130><CENTER>Local Address</CENTER>
</TD><TD WIDTH=130><CENTER>Foreign Address</CENTER>
</TD><TD WIDTH=520>Description</TD></TR>
<TR><TD WIDTH=130><CENTER><I>localIP.lport
<BR>
localIP.lport<BR>
*.lport</I></CENTER>
</TD><TD WIDTH=130><CENTER><I>foreignIP.fport<BR>
*.*<BR>
* *</I></CENTER>
</TD><TD WIDTH=520>restricted to one client (normally not supported)<BR>
restricted to connections arriving on one local interface: <I>localIP<BR>
</I>receives all connections sent to <I>lport</I>
</TD></TR>
</TABLE>
</CENTER>
<P>
<CENTER><B>Figure 18.22</B> Specification
of local and foreign IP addresses and port number for TCP server.</CENTER>
<H4>Incoming Connection Request Queue</H4>
<P>
A concurrent server invokes a new process to handle
each client, so the listening server should always be ready to
handle the next incoming connection request. That's the underlying
reason for using concurrent servers. But there is still a chance
that multiple connection requests arrive while the listening server
is creating a new process, or while the operating system is busy
running other higher priority processes. How does TCP handle these
incoming connection requests while the listening application is
busy? In Berkeley-derived implementations the following rules
apply.
<P>
<OL>
<LI>Each listening end point has a fixed length queue
of connections that have been accepted by TCP (i.e., the three-way
handshake is complete), but not yet accepted by the application.
<P>
Be careful to differentiate between TCP accepting
a connection and placing it on this queue, and the application
taking the accepted connection off this queue.
<P>
<LI>The application specifies a limit to this queue,
commonly called the backlog. This backlog must be between 0 and
5, inclusive. (Most applications specify the maximum value of 5.)
<P>
<LI>When a connection request arrives (i.e., the SYN
segment), an algorithm is applied by TCP to the current number
of connections already queued for this listening end point, to
see whether to accept the connection or not. We would expect the
backlog value specified by the application to be the maximum number
of queued connections allowed for this end point, but it's not
that simple. Figure 18.23 shows the relationship between the backlog
value and the real maximum number of queued connections allowed
by traditional Berkeley systems and Solaris 2.2.
<P>
<CENTER><a name="fig_18_23"><TABLE BORDER=1></a>
<TR><TD WIDTH=130><CENTER>Backlog value</CENTER></TD>
<TD COLSPAN=2 WIDTH=250><CENTER>Max # of queued connections</CENTER>
</TD></TR>
<TR><TD WIDTH=130></TD><TD WIDTH=150><CENTER>Traditional BSD</CENTER>
</TD><TD WIDTH=110><CENTER>Solaris 2.2</CENTER></TD></TR>
<TR><TD WIDTH=130><CENTER>0
<BR>
1<BR>
2<BR>
3<BR>
4<BR>
5</CENTER>
</TD><TD WIDTH=150><CENTER>1<BR>
2<BR>
4<BR>
5<BR>
7<BR>
8</CENTER>
</TD><TD WIDTH=110><CENTER>0<BR>
1<BR>
2<BR>
3<BR>
4<BR>
5</CENTER>
</TD></TR>
</TABLE>
<P>
<B>Figure 18.23</B> Maximum number
of accepted connections allowed for listening end point.</CENTER>
<P>
Keep in mind that this backlog value specifies only
the maximum number of queued connections for one listening end
point, all of which have already been accepted by TCP and are
waiting to be accepted by the application. This backlog has no
effect whatsoever on the maximum number of established connections
allowed by the system, or on the number of clients that a concurrent
server can handle concurrently.
<P>
<FONT SIZE=-1>The Solaris values in this figure are what we expect.
The traditional BSD values are (for some unknown reason) the backlog
value times 3, divided by 2, plus 1.</FONT>
<P>
<LI>If there is room on this listening end point's
queue for this new connection (based on Figure 18.23), the TCP
module ACKs the SYN and completes the connection. The server application
with the listening end point won't see this new connection until
the third segment of the three-way handshake is received. Also,
the client may think the server is ready to receive data when
the client's active open completes successfully, before the server
application has been notified of the new connection. (If this
happens, the server's TCP just queues the incoming data.)
<P>
<LI>If there is not room on the queue for the new
connection, TCP just ignores the received SYN. Nothing is sent
back (i.e., no RST segment). If the listening server doesn't get
around to accepting some of the already accepted connections that
have filled its queue to the limit, the client's active open will
eventually time out.
</OL>
<P>
We can see this scenario take place with our sock
program. We invoke it with a new option (<TT>-O</TT>)
that tells it to pause after creating the listening end point,
before accepting any connection requests. If we then invoke multiple
clients during this pause period, it should cause the server's
queue of accepted connections to fill, and we can see what happens
with <TT>tcpdump</TT>.
<P>
<TT>bsdi % <B>sock -a -v -q1 -O30 7777</B></TT>
<P>
The <TT>-q1</TT> option sets
the backlog of the listening end point to 1, which for this traditional
BSD system should allow two pending connection requests (<a href="#fig_18_23">Figure 18.23</a>).
The <TT>-O30</TT> option causes the
program to sleep for 30 seconds before accepting any client connections.
This gives us 30 seconds to start some clients, to fill the queue.
We'll start four clients on the host <TT>sun</TT>.
<P>
Figure 18.24 shows the <TT>tcpdump</TT>
output, starting with the first SYN from the first client. (We
have removed the window size advertisements and MSS announcements.
We have also marked the client port numbers in bold when the TCP
connection is established-the three-way handshake.)
<P>
The first client's connection request from port 1090
is accepted by TCP (segments 1-3). The second client's connection
request from port 1091 is also accepted by TCP (segments 4-6).
The server application is still asleep, and has not accepted either
connection yet. Everything has been done by the TCP module in
the kernel. Also, the two clients have returned successfully from
their active opens, since the three-way handshakes are complete.
<CENTER>
<a name="fig_18_24"><TABLE></a>
<TR><TD WIDTH=25>1</TD><TD WIDTH=210><TT>0.0</TT>
</TD><TD WIDTH=525><TT>sun.1090 &gt; bsdi.7777: S 1617152000:1617152000(0)</TT>
</TD></TR>
<TR><TD WIDTH=25>2</TD><TD WIDTH=210><TT>0.002310 ( 0.0023)</TT>
</TD><TD WIDTH=525><TT>bsdi.7777 &gt; sun.1090: S 4164096001:4164096001(0)
<BR>
ack 1617152001 </TT>
</TD></TR>
<TR><TD WIDTH=25>3</TD><TD WIDTH=210><TT>0.003098 ( 0.0008)</TT>
</TD><TD WIDTH=525><TT>sun.1090 &gt; bsdi.7777: . ack 1</TT></TD>
</TR>
<TR><TD WIDTH=25>4</TD><TD WIDTH=210><TT>4.291007 ( 4.2879)</TT>
</TD><TD WIDTH=525><TT>sun.1091 &gt; bsdi.7777: S 1617792000:1617792000(0)</TT>
</TD></TR>
<TR><TD WIDTH=25>5</TD><TD WIDTH=210><TT>4.293349 ( 0.0023)</TT>
</TD><TD WIDTH=525><TT>S 4164672001:4164672001(0) ack 1617792001</TT>
</TD></TR>
<TR><TD WIDTH=25>6</TD><TD WIDTH=210><TT>4.294167 ( 0.0008)</TT>
</TD><TD WIDTH=525><TT>sun.1091 &gt; bsdi.7777: . ack 1</TT></TD>
</TR>
<TR><TD WIDTH=25>7</TD><TD WIDTH=210><TT>7.131981 ( 2.8378)</TT>
</TD><TD WIDTH=525><TT>sun.1092 &gt; bsdi.7777: S 1618176000:1618176000 (0)</TT>
</TD></TR>
<TR><TD WIDTH=25>8</TD><TD WIDTH=210><TT>10.556787 ( 3..4248)</TT>
</TD><TD WIDTH=525><TT>sun.1093 &gt; bsdi.7777: S 1618688000:1618688000 (0)</TT>
</TD></TR>
<TR><TD WIDTH=25>9</TD><TD WIDTH=210><TT>12.695916 ( 2..1391)</TT>
</TD><TD WIDTH=525><TT>sun.1092 &gt; bsdi.7777: S 1618176000:1618176000 (0)</TT>
</TD></TR>
<TR><TD WIDTH=25>10</TD><TD WIDTH=210><TT>16.195772 ( 3..4999)</TT>
</TD><TD WIDTH=525><TT>sun.1093 &gt; bsdi.7777: S 1618688000:1618688000 (0)</TT>
</TD></TR>
<TR><TD WIDTH=25>11</TD><TD WIDTH=210><TT>24.695571 ( 8..4998)</TT>
</TD><TD WIDTH=525><TT>sun.1092 &gt; bsdi.7777: S 1618176000:1618176000 (0)</TT>
</TD></TR>
<TR><TD WIDTH=25>12</TD><TD WIDTH=210><TT>28.195454 ( 3.4999)</TT>
</TD><TD WIDTH=525><TT>sun.1093 &gt; bsdi.7777: S 1618688000:1618688000 (0)</TT>
</TD></TR>
<TR><TD WIDTH=25>13</TD><TD WIDTH=210><TT>28.197810 ( 0.0024)</TT>
</TD><TD WIDTH=525><TT>bsdi.7777 &gt; sun.1093: S 4167808001:4167808001 (0)
<BR>
ack 1618688001</TT>
</TD></TR>
<TR><TD WIDTH=25>14</TD><TD WIDTH=210><TT>28.198639 ( 0.0008)</TT>
</TD><TD WIDTH=525><TT>sun.1093 &gt; bsdi.7777: ack 1</TT></TD>
</TR>
<TR><TD WIDTH=25>15</TD><TD WIDTH=210><TT>48.694931 (20.4963)</TT>
</TD><TD WIDTH=525><TT>sun.1092 &gt; bsdi.7777: S 1618176000:1618176000(0)</TT>
</TD></TR>
<TR><TD WIDTH=25>16</TD><TD WIDTH=210><TT>48.697292 ( 0.0024)</TT>
</TD><TD WIDTH=525><TT>bsdi.7777 &gt; sun.1092: S 4190496001: 417 049 6001(0)
<BR>
ack 1618176001</TT>
</TD></TR>
<TR><TD WIDTH=25>17</TD><TD WIDTH=210><TT>48.698145 ( 0.0009)</TT>
</TD><TD WIDTH=525><TT>sun.1092 &gt; bsdi.7777: ack 1</TT></TD>
</TR>
</TABLE>
<P>
<B>Figure 18.24</B> <TT>tcpdump</TT>
output for backlog example.</CENTER>
<P>
We try to start a third client in segment 7 (port
1092), and a fourth in segment 8 (port 1093). TCP ignores both
SYNs since the queue for this listening end point is full. Both
clients retransmit their SYNs in segments 9, 10, 11, 12, and 15.
The fourth client's third retransmission is accepted (segments
12-14) because the server's 30-second pause is over, causing the
server to remove the two connections that were accepted, emptying
its queue. (The reason it appears this connection was accepted
by the server at the time 28.19, and not at a time greater than
30, is because it took a few seconds to start the first client
[segment 1, the starting time point in the output] after starting
the server.) The third client's fourth retransmission is then
accepted (segments 15-17). The fourth client connection (port
1093) is accepted by the server before the third client connection
(port 1092) because of the timing interactions between the server's
30-second pause and the client's retransmissions.
<P>
<FONT SIZE=-1>We would expect the queue of accepted connections
to be passed to the application in FIFO (first-in, first-out)
order. That is, after TCP accepts the connections on ports 1090
and 1091, we expect the application to receive the connection
on port 1090 first, and then the connection on port 1091. But
a bug has existed for years in many Berkeley-derived implementations
causing them to be returned in a LIFO (last-in, first-out) order
instead. Vendors have recently started fixing this bug, but it
still exists in systems such as SunOS 4.1.3.</FONT>
<P>
TCP ignores the incoming SYN when the queue is full,
and doesn't respond with an RST, because this is a soft error,
not a hard error. Normally the queue is full because the application
or the operating system is busy, preventing the application from
servicing incoming connections. This condition could change in
a short while. But if the server's TCP responded with a reset,
the client's active open would abort (which is what we saw happen
if the server wasn't started). By ignoring the SYN, the server
forces the client TCP to retransmit the SYN later, hoping that
the queue will then have room for the new connection.
<P>
A subtle point in this example, which is found in
most TCP/IP implementations, is that TCP accepts an incoming connection
request (i.e., a SYN) if there is room on the listener's queue,
without giving the application a chance to see who it's from (the
source IP address and source port number). This is not required
by TCP, it's just the common implementation technique (i.e., the
way the Berkeley sources have always done it). If an API such
as TLI (<a href="introduc.htm#1_15" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/introduc.htm#1_15">Section 1.15</a>) gives the application a way to learn when
a connection request arrives, and then allows the application
to choose whether to accept the connection or not, be aware that
with TCP, when the application is supposedly told that the connection
has just arrived, TCP's three-way handshake is over! Other transport
layers may be implemented to provide this separation to the application
between arrival and acceptance (i.e., the OSI transport layer)
but not TCP.
<P>
<FONT SIZE=-1>Solaris 2.2 provides an option that prevents TCP
from accepting an incoming connection request until the application
says so (<TT>tcp_eager_listeners</TT> in <a href="append_e.htm#E_4" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/append_e.htm#E_4">Section E.4</a>).</FONT>
<P>
This behavior also means that a TCP server has no
way to cause a client's active open to fail. When a new client
connection is passed to the server application, TCP's three-way
handshake is over, and the client's active open has completed
successfully. If the server then looks at the client's IP address
and port number, and decides it doesn't want to service this client,
all the server can do is either close the connection (causing
a FIN to be sent) or reset the connection (causing an RST to be
sent). In either case the client thought everything was OK when
its active open completed, and may have already sent a request
to the server.
<a name="18_12"><H3>18.12 Summary</H3></a>
<P>
Before two processes can exchange data using TCP,
they must establish a connection between themselves. When they're
done they terminate the connection. This chapter has provided
a detailed look at how connections are established using a three-way
handshake, and terminated using four segments.
<P>
We used <TT>tcpdump</TT> to show
all the fields in the TCP header. We've also seen how a connection
establishment can time out, how resets are sent, what happens
with a half-open connection, and how TCP provides a half-close,
simultaneous opens, and simultaneous closes.
<P>
Fundamental to understanding the operation of TCP
is its state transition diagram. We've followed through the steps
involved in connection establishment and termination, and the
state transitions that take place. We also looked at the implications
of TCP's connection establishment on the design of concurrent
TCP servers.
<P>
A TCP connection is uniquely defined by a 4-tuple:
the local IP address, local port number, foreign IP address, and
foreign port number. Whenever a connection is terminated, one
end must maintain knowledge of the connection, and we saw that
the TIME_WAIT state handles this. The rule is that the end that
does the active open enters this state for twice the implementation's
MSL.
<H4>Exercises</H4>
<P>
<B>18.1</B> In <a href="#18_2">Section 18.2</a> we
said that the initial sequence number (ISN) normally starts at
1 and is incremented by 64,000 every half-second and every time
an active open is performed. This would imply that the low-order
three digits of the ISN would always be 001. But in <a href="#fig_18_3">Figure 18.3</a>
these low-order three digits are 521 in each direction. What's
going on?
<P>
<B>18.2</B> In <a href="#fig_18_15">Figure 18.15</a> we
typed 12 characters and saw 13 bytes sent by TCP. In <a href="#fig_18_16">Figure 18.16</a>
we typed eight characters but TCP sent 10 bytes. Why was 1 byte
added in the first case, but 2 bytes in the second case?
<P>
<B>18.3</B> What's the difference
between a half-open connection and a half-closed connection?
<P>
<B>18.4</B> If we start our sock
program as a server, and then terminate it (without having a client
connect to it), we can immediately restart the server. This implies
that it doesn't go through the 2MSL wait state. Explain this in
terms of the state transition diagram.
<P>
<B>18.5</B> In <a href="#18_6">Section 18.6</a> we
showed that a client cannot reuse the same local port number while
that port is part of a connection in the 2MSL wait. But if we
run our sock program twice in a row as a client, connecting to
the daytime server, we can reuse the same local port number. Additionally,
we're able to create a new incarnation of a connection that should
be in the 2MSL wait. What's going on?
<P>
<TT>sun % <B>sock -v bsdi daytime
<BR>
</B>connected on 140.252.13.33.1163 to 140.252.13.35.13
<BR>
Wed Jul 7 07:54:51 1993<BR>
connection closed by peer</TT>
<P>
<TT>sun % <B>sock -v -bll63 bsdi
daytime</B> <I>reuse same
local port number<BR>
</I>connected on 140.252.13.33.1163 to 140.252.13.35.13
<BR>
Wed Jul 707:55:01 1993<BR>
connection closed by peer</TT>
<P>
<B>18.6</B> At the end of <a href="#18_6">Section 18.6</a>
when describing the FIN_WAIT_2 state, we mentioned that many
implementations move a connection from this state into the CLOSED
state if the application did a complete close (not a half-close)
after just over 11 minutes. If the other end (in the CLOSE_WAIT
state) waited 12 minutes before issuing its close (i.e., sending
its FIN), what would its TCP get in response to the FIN?
<P>
<B>18.7</B> Which end of a telephone
conversation does the active open, and which does the passive
open? Are simultaneous opens allowed? Are simultaneous closes
allowed?
<P>
<B>18.8</B> In <a href="#fig_18_6">Figure 18.6</a> we
don't see an ARP request or an ARP reply. Obviously the hardware
address for host <TT>svr4</TT> must be in
the ARP cache on <TT>bsdi</TT>. What would
change in this figure if this ARP cache entry was not present?
<P>
<B>18.9</B> Explain the following
<TT>tcpdump</TT> output. Compare it with <a href="#fig_18_13">Figure 18.13</a>.
<P><CENTER>
<TABLE>
<TR><TD WIDTH=15>1</TD><TD WIDTH=170><TT>0.0</TT>
</TD><TD WIDTH=525><TT>solaris.32990 &gt; bsdi.discard: S 40140288:40140288(0)<BR>
win 8760 &lt;mss 1460&gt;</TT>
</TD></TR>
<TR><TD WIDTH=15>2</TD><TD WIDTH=170><TT>0.003295 (0.0033)</TT>
</TD><TD WIDTH=525><TT>bsdi.discard &gt; solaris.32990: S 4208081409:4208081409 (0)
<BR>
ack 40140289 win 4096 &lt;mss 1024&gt;</TT>
</TD></TR>
<TR><TD WIDTH=15>3</TD><TD WIDTH=170><TT>0.419991 (0.4167)</TT>
</TD><TD WIDTH=525><TT>solaris.32990 &gt; bsdi.discard: P 1:257(256) ack 1 win 9216</TT>
</TD></TR>
<TR><TD WIDTH=15>4</TD><TD WIDTH=170><TT>0.449852 (0.0299)</TT>
</TD><TD WIDTH=525><TT>solaris.32990 &gt; bsdi.discard: F 257:257(0) ack 1 win 9216</TT>
</TD></TR>
<TR><TD WIDTH=15>5</TD><TD WIDTH=170><TT>0.451965 (0.0021)</TT>
</TD><TD WIDTH=525><TT>bsdi.discard &gt; solaris.32990: . ack 258 win 3840</TT>
</TD></TR>
<TR><TD WIDTH=15>6</TD><TD WIDTH=170><TT>0.464569 (0.0126)</TT>
</TD><TD WIDTH=525><TT>bsdi.discard &gt; solaris.32990: F 1:1(0) ack 258 win 4096</TT>
</TD></TR>
<TR><TD WIDTH=15>7</TD><TD WIDTH=190><TT>0.720031 (0.2555)</TT>
</TD><TD WIDTH=525><TT>solaris.32990 &gt; bsdi.discard: . ack 2 win 9216</TT>
</TD></TR>
</TABLE>
</CENTER>
<P>
<B>18.10</B> Why doesn't the
server in <a href="#fig_18_4">Figure 18.4</a> combine the ACK of the client's FIN with
its own FIN, reducing the number of segments to three?
<P>
<B>18.11</B> In <a href="#fig_18_16">Figure 18.16</a>
why is the sequence number of the RST 26368002?
<P>
<B>18.12</B> Does TCP's querying
the link layer for the MTU violate the spirit of layering?
<P>
<B>18.13</B> Assume in <a href="dns_the.htm#fig_14_16" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/dns_the.htm#fig_14_16">Figure 14.16</a>
that each DNS query is issued using TCP instead of UDP.
How many packets are exchanged?
<P>
<B>18.14</B> With an MSL of 120
seconds, what is the maximum at which a system can initiate new
connections and then do an active close?
<P>
<B>18.15</B> Read RFC 793 to
see what happens when an end point that is in the TIME_WAIT state
receives a duplicate of the FIN that placed it into this state.
<P>
<B>18.16</B> Read RFC 793 to
see what happens when an end point that is in the TIME_WAIT state
receives an RST.
<P>
<B>18.17</B> Read the Host Requirements
RFC to obtain the definition of a <I>half-duplex</I> TCP close.
<P>
<B>18.18</B> In <a href="introduc.htm#fig_1_8" tppabs="http://www.uic.rnd.runnet.ru/doc/inet/tcp_stevens/introduc.htm#fig_1_8">Figure 1.8</a> we
said that incoming TCP segments are demultiplexed based on the
destination TCP port number. Is that correct?
</BODY>
</HTML>
